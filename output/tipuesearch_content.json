{"pages":[{"url":"pages/about.html","text":"","tags":"misc","title":"About"},{"url":"pages/bookshelf.html","text":"Physics Books Introduction to Solid State Physics. by Kittle ( pdf ) Classical Electrodynamics. by John David Jackson Modern Quantum Mechanics. by Sakurai Statistical Mechanics. by Pathria Introduction to Elementary Particle Physics. by Griffiths Introduction to Quantumn Field Theory. by Perskin Computational Physics. by Wengan Ma ( pdf ) Classical Dynamics of Particles and Systems. by Thornton Marion Classical Mechanics. by Goldstein Introduction to Statistics and Data Analysis for Physicist. By Gerhard Bohm, etc. /Users/lwen/Documents/Books/dataAnalysisForPhysicist.pdf Data Analysis In High Energy Physics. By Roger Barlow, etc. /Users/lwen/Documents/Books/DataAnalysisInHighEnergyPhysics Geophysics Books Seismic Data Analysis. by Yilmaz Physics of The Earth. by Stacey and Davis The Mechanics of Earthquakes and Faulting. by Christopher H. Scholz Quantitative Seismology. by Keiiti Aki, Paul G. Richards Elastic Wave Propagation and Generation in Seismology. by Jose Pujol Structural Geology. by Haakon Fossen Quantitative Seismology. by Aki and Paul (first edition in Chinese, second volume, pdf ) Introduction to Seismology. by Peter Shearer (seconde edition, pdf ) 52 Things You Should Know about Geophysics. by Agile Libre Computer Science Books Data Structure And Algorithms Using C++. Classic Shell Scripting. by Arnold & Nelson C++ Primer. by Lippman, Lajoie, Moo Numerical Recipe. by Teukolsky etc. (third edition, C++) Python Programming: A Introduction to Computer Science. by Zelle Linux Commands, Editor and Shell Programming. (in Chinese) Python Cookbook. by Beazley and Jones Practical Vim. by Neil Accelerated C++. by Koenig & Moo Learn Python the Hard way. by Shaw PHP/MySQL. by Murach Code Complete. by Steve McConnell JaveScripts Tutorial. by Johnanth etc. Effective C++. by Meyer(in office) Matlab: An Introduction with Applications. by Amos Gilat The Quick Python Book. (second edition) by Vernol Ceder Design Patterns. by Erich Gamma, etc. Thinking in C++. by Bruce Eckel SQL: the visual quickstart Guide. by Fehily gdrive/books Write Idiomatic Python3. by Jeff( cheatsheet ) gdrive/books Data abstraction and problem solving with C++. by Frank M. Carrano More Effective C++. by Meyer Effective STL. by Meyer C++ Design Patterns and Derivatives Pricing. by Mark Joshi /Users/gdrive/books Operating systems: design and implementation. by Andrew S. Tanenbaum /Users/gdrive/books API Design for C++. by Martin /Users/gdrive/books Python for Unix and Linux System Administration. by Noah Gift etc. /Users/gdrive/books Python for Finance. C++ Cookbook by Stephens et.al. (location: google drive/books) Math/Statistics Books Practical Math Manual (in Chinese). by Qixiao Ye & Yonghuan Shen Statistical Concepts and Methods. by Johnson A Student's Guide to Vectors and Tensors. by Daniel Fleisch Introduction to Statistical Learning with Application in R. by Gareth James, etc.: /Users/lwen/Documents/Books/ISL_R.pdf Quantumn Theory, Groups and Representations: /Users/lwen/Documents/Books/QuantumnTheory_Groups_Representations.pdf A Course in Probability Theory. by Kai Lai Chung Probability: Theory and Examples(solution manual included). by Durrett /Users/lwen/Documents/Math275 Probability with Martinggales. by Williams /Users/.../Math275C A Probability Path. by Resnick /Users/.../Math275C Probability and Measure. by Billingsley /Users/.../Math275C 150 Mostly Asked Questions on Quant Interview Green face book on Qunat Interview. by Xingfeng Zhou Data Science Data Sciecne from Scratch. by Joel Grus gdrive/books Python for Data Analysis. by Wes Kinnedy gdrive/books Some Notes & Good Stuff Manuel's ROOT tips and tricks ( Manuel's rootlogon.C ) Working Example of Eistein Summation curviliar coordinates conversion rootlogon.C How to write makefile by Hao Chen (in Chinese) Group Theory for Physicist Notes: /Users/lwen/Documents/Books/grouptheorynotes.pdf Logs:","tags":"misc","title":"Books Collection"},{"url":"pages/task-magnagement.html","text":"Questions to Answer: How to handle exceptions in C++ and python? ( link ) How to design good/reusable software? (design patterns) How to properly use const key word in C++? 2016-03-20: In class definition, if you want this function not to change any data member, you should declare this function like bool function(int i, int j) const; In function declaration, const string& will enable you to pass in not only a regular string variable but also the string literal. If you dont add const before string , it implicitly tells the compiler that the value will be changed so temporal object cannot be accepted(changes cannot be strored anywhere). If you want a local variable not to be changed by any way. Flow-related questions.(why 2nd order event plane can only be used for even correlation) Chiral symmetry broken? How to write a solver(analysis pipline and kaggle solver) How to exercise my database skills(SQL)? Figure out how SU(3) is related to QCD, etc. Skills to develop: Coding: Data analysis in python.pandas?? (work through Python for data analysis exercise, 45 mins every day) 2016-03-20: will do in next quater with Kaggle examples. C++ development knowledge?(work through the thinking in C++ exercise, 45 mins every day) 2016-03-20: no need. Just pick some time to read it through. Finished CS32, which is great, check out some notes of that course on this site. Develop Algorithms understanding, and start coding leet code. 2016-03-20: need to check algorithm course on coursera(Prof. Roughgarden, Standford), but we still can go through old videos. Develop my own bash shell script cheatsheet.(shell_script_cheatsheet.md) Develop a database server for chiral effects data points. How to do parallel computing in sckit-learn? Multithreaded? 2016-03-20: need to look into it soon. Read through XGB python test framework and this Dynamic programming and greedy algorithms?(Take notes and practice)(MIT CS6.006 videos 4 lectrues on dynamic programming) How to develop unit-test code in Python and C++. Need examples and practice and interview questions. Know the fundamental concepts in Computer Operating Systems. Machine Learning: Reading book in physics machine learning, and write notes about the examples. (odd weekday, 45 mins before bed) Review and reformat the previous notes on Introduction to Machine Learning. (Fridays, 1 hr) Long term goal is to read through the Elements of Statistical Learning / Pattern Reconigtion, take notes() Learn to use KDE, itemgetter() sklearn.GridSearchCV(clf, param_grid, nfold = 20); grid_search.fit; grid_search.grid_scores_ can be used for grid search. But, random search may result in same result(60 times).: The moral of the story is: if the close-to-optimal region of hyperparameters occupies at least 5% of the grid surface, then random search with 60 trials will find that region with high probability. Learn to use os module write note on how to install sklearn-neuralnetwork How to use OneHotEncoder in practice How to use multi-thread feature of scikit-learn xgb early stopping Pearson correlation Randomize predictor selection to see the effect* Center and normalize your data Left-out-one encoding When to use standardlization Keras/Theano/Lasagne/FM algorithm/ Regularized greedy tree.(Tong Zhang's) Two talks on data science: Owen Zhang's Linkedin and Jeon-yoon Lee's Kaggler.com Feature importance selection VM usage Visulization. Books to read: Quick view: Data Science from scratch Machine learning in python(*) Heads up design pattern(for interview preparation) Cracking the code interview [Beauty of coding])(https://drive.google.com/file/d/0B3ZmSZ7JPYZ6anBjM2ZjU0ZLdGs/view?usp=sharing) Data structure and algorithms in C++ Courses to take: CS32: Introduction to Computer ScienceII(project3/4 could be put on resume; webpages needed) Stochastic Process. Math171(2017 Spring) Stochastic Process Math275C(2016 Spring) CS33: Introduction to computer system(Open every quarter?) Stat231: Machine Learning(2016-1017 Fall)(could be put on resume) Stat202C: Monte Carlo for Optimization.(2017 Spring)(could be put on resume) U. of Washington Specialization in Data Science. (2017 Spring to Summer, 6 courses)(could be put on resume) C183: Statistical models in finance(2017 Spring) Logs: 2016-03-25: I want to learn(by the end of April): unitest in python for my framework; document my kaggle pipline; Greedy Algorithms( a quick view ); Dynamic Programming... 2016-03-27: Add code to normalize our feature data; how to organize the categorical data in svm application, normalization, like embark location in Titanic(1, 2, 3 for south ampton, ...)? 2016-04-04: Furbished my resume for two versions(quant/SE/DS). 2016-05-20: blog ; Backtracing(videos); On wechat, I saved a bookmark which tells about howto improve your python step by step.","tags":"misc","title":"Task Management"},{"url":"pages/mis.html","text":"Some useful tutorials get_file_list.pl usage matplotlib tutorial: /Users/lwen/Documents/python_examples/AnatomyOfMatplotlib-master python example code: /Users/lwen/Documents/python_examples sklearn example code: /Users/lwen/Documents/sklearn_examples ROOT example code: /Users/lwen/Documents/ROOT_Test How to color output in C++ Flow analysis in heavy ion collisions ROOT tips STAR S&C tips Bibiliography management with bibtex Interesting stuff: 3D view of STAR detector: /Users/lwen/Documents/STAR_images Some notes: Logistic classification Anomaly detection Support vector machine Design patterns study note I CS32 miscellaneous information Some object oriented programming tips Stringstream writeup CS32 Slides from Carey Nachenberg Operating system concept notes Factorization Machines Algorithms and data structure cheatsheet conda cheatsheet Data structure and algorithms basics How to deal with systematic error StEvent documentation StMcEvent documentation StAssociationMaker documentation C++ cheat sheet C++ template notes or Carey's notes C++/C static keyword Python Cheatsheet Stanford Database notes Java Notes for C++ Programmers (location: google drive) C++ Review Notes (location: desktop, google drive) Operating System Notes (location: desktop, google drive) Database Notes (location: desktop, google drive) Book notes: The hunting of the quark Lab Management 180A Lab NuQCD Servers Life Management Travel Checklist My United Mileage Plus ID: WW151698 My AA Advantage Number: 01A0BB8","tags":"misc","title":"Miscellaneous"},{"url":"pages/research.html","text":"Nuclear Physics Strangeness Production in Beam Energy Scan Phase I at RHIC/STAR Omega yields in AuAu 14.5 GeV Collisions Phi yields in AuAu 14.5 GeV Collisions Chiral Effects Pion \\(\\gamma\\) correlation in heavy ion collisions Search for CVE using \\(\\Lambda\\) -proton correlation Logs: 2016-03-20: Prepare the data for feng's comparison code. 2016-06-13: Thesis-related .bib file if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"misc","title":"Research"},{"url":"eval-algo.html","text":"Evaluating a Learning Algorithm What is variance-bias tradeoff? High variance may cause underfitting; High bias may cause overfitting; How to improve my learning algorithm: Get more training examples: fix high variance Try smaller sets of features: fix high variance Try getting additional features: fix high bias Try add polynomial features: fix high bias Try decrease $$\\lambda$$ : fix hgih bias Try increasing $$\\lambda$$ : fix high variance Learning Diagnostic: definition: a test you can run to gain insight what is/isn't working; Evaluting a hypothesis: Split dataset into training set and test set(70%/30%, randomize ordering of data); Compute test error: $$J_{test}(\\Theta)=\\frac{1}{2m_{test}}...$$ also the case for classificiation problems; Miscalssification error(0/1 misclaffication error): $$err(H_{\\Theta}(x), y) = 1/0 $$ based on if prediction is correct or not; $$Test_err = 1/m\\sum\\limits&#94;{m_{test}}_{i = 1} err_i$$ Model selection and train/validation/test sets: choose different models(polynomial ) to see how the test dataset performs: Training/cross validation/test set(60/20/20, training error/cross validation error/ test error): get hypothesis parameters; apply these hypothesis on cv data set(other wise the degree of polynomial is fittd to test dataset); apply the optimal hypothesis on test data set to estimate generalization error for the model selected; Diagnosing bias vs. variance: plot degree of poly. vs. error: distinguish bias/variance: bias: high-training error, high-cross validation error variance: low-training error, high-cross validation error Regularization and bias/variance: large $$\\lambda$$ : underfitting; intermediate $$\\lambda$$ : just right; small $$\\lambda$$ : overfitting; like in logistics regress fitting, try different $$\\lambda$$ from 0 to 10(for example) and follow previous procedures: Learning curves: learning curves: error vs. m high bias: converge for both traning error and cv error(no help to increase the sample number) high variance: big gap between training error and cv error(it helps to get more samples) How to choose neural network archetect small: underfitting and computationally cheap; large struture: overfitting and can be fixed by regularization; if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"misc","title":"Evaluating a Learning Algorithm"},{"url":"paper-reading.html","text":"General topic in heavy ion collisions Science 332 1525, Nu's comparison between STAR's result and Lattice QCD to derive \\(T_c\\) . Basically use the suscepibility analysis to compare one-parameter( \\(T_c\\) ) model calculation to finally find out the most fit parameter. Strangeness production The tale of the Hagedorn temperature explains the concept of Hagedorn tmeparature in the context of hadron collisions and extend it to Quark Matter phase. SBM(strapbost model) is sucessful in predicting the particle productions in hadron collisions. But why there is no absolute hot temperature? if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"misc","title":"Paper Reading"},{"url":"cpp-derivative-pricing.html","text":"Use smart pointers; Pass vector as reference and it would be as fast as using pointer. How to generate an reproducible(pseudo-random) numbers mathematically? Check the chapter about the random number generators.","tags":"misc","title":"Notes on _CPP Design pattern and Derivatives Pricing_"},{"url":"intro-ml.html","text":"Introduction Unsupervised Learning Problems i. Clustering(Clustering algorithms); ii. Cocktail Party Problem(cocktail party algorithms): 2 speakers, 2 microphones with different distances separate one from another one or separate music from combinition","tags":"misc","title":"Intro. to ML by Andrew Ng"},{"url":"large-scale-ml.html","text":"Large scale machine learning It is not who has the best algorithm that wins, it is who has the most data. Learning with large datasets: plot error vs. training set size(J_train, J_cv) Stochastic Gradient Descent: Gradient descent is computationally expensive(batch gradient descent); stochastic gradient descent: $$cost(\\theta, (x&#94;i, y&#94;i))= 0.5\\times(h_\\theta(x&#94;i) - y&#94;i)&#94;2$$ $$J_{train}(\\theta) = 1/m \\sum\\limits_{i=1}&#94;mcost(\\theta, (x&#94;i, y&#94;i))$$ First of all, randomly shuffle dataset: matlab pseudocode for i = 1:m theta(j) = theta(j) - alpha * (h_theta(x(i))-y(i))*x(i) end $$\\theta_j = \\theta_j - \\alpha\\frac{\\partial}{\\partial \\theta_j}cost(\\theta, (x&#94;i, y&#94;i))$$ Usually iterate 1-10 times Mini-Batch Gradient Descent: batch gradient descent: all of m examples stochastic gradient descent: 1 example in each iteration mini-batch gradient descent: b examples in each iteration(m = 10, 2-200) why mini-batch better over stochastic: parallelize computation, if vectorization is well done?? Stochastic gradient descent covergence: every 1000 iterations, plot cost(\\ehta,(x&#94;i, y&#94;i)) averaged over the last 1000 examples processed by algorithm. - the first graph red mean smaller alpha, second graph, red means average over 5000 examples, third one is just not working for two different - Keeping alpha constant is pretty common stratedgy or u can gradully decrease its value so you can get better parameters for global minimum 6. Online Learning: - online learning setting: shipping service website where user comes , specifies origin and destinations, you offer to ship their package for some asking price, and users sometimes choose to use your service sometimes not. - Features x capture properties of user, of origin/destination and asking price, We want to learn $$p(y = 1|x;\\theta)$$ to optimize price (using logistic regression) Repeat forever{ Get(x, y ) corresponding to user; Update $$\\theta$$ using(x,y) theta(j) = theta(j) - alpha*x(j)*(h_theta(x) - y) j = 0-n } predict CTR(click through rate) and show the 10 phones they are mostly likely to click on, like sell the phone (match search queries) Mapreduce and Data Parallelism Batch gradient descent: machine1, use first 100 examples; $$temp_j&#94;1 = \\sum\\limits_{i=1}&#94;{100}(h_\\theta(x&#94;i) - y&#94;i)x_j&#94;i$$ ... $$\\theta_j = \\theta_j - \\alpha\\sum(h_\\theta(x&#94;i) - y&#94;i)x&#94;i_j$$ by combing results from all of the computers multi-core machines can also been used if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"misc","title":"Large Scale Machine Learning"},{"url":"learn-neural-network.html","text":"Learn Neural Network(for classification problems) Cost function: L = total no. of layers in network $$s_l$$ = no. of units in layer 1(not counting bias unit) Binary classification(y = 0 or 1): Multi-class classification(K classes, k dimensional vector, k >= 3): $$J(\\Theta) = -\\frac{1}{m}[\\sum\\limits_{i=1}&#94;{m}\\sum\\limits_{k=1}&#94;{K}y_k&#94;{i}log(h_\\Theta(x&#94;{(i)}))_k+(1-y_k&#94;{i})log(1-h_\\Theta(x&#94;{(i)}))_k]+\\frac{\\lambda}{2m}\\sum\\limits_{l=1}&#94;{L-1}\\sum\\limits_{j=1}&#94;{s_{l+1}}\\sum\\limits_{i=1}&#94;{s_l}(\\Theta_{ji}&#94;{(l)})&#94;2$$ Back-propagation: Intuition: $$\\delta_j&#94;l = (\\Theta&#94;l)&#94;T\\delta&#94;{l+1}.*g'(z&#94;l)$$ , where $$g'(z&#94;l)$$ is the derivative with respect to $$z$$ , which equals $$a&#94;l.*(1-a&#94;l)$$ Good to know: if $$\\lambda = 0$$ , $$\\frac{\\partial J(\\Theta)}{\\partial \\Theta_{ji}&#94;l} = a_j&#94;l\\delta_i&#94;{l+1}$$ Algorithms: Set $$\\Delta_{ji}&#94;l = 0$$ Intuition: Implementation tips: Unroll and reshape a matrix: Gradient Checking: 1. numberical compute gradient; 2. check gradApprox ~ DVec(from backpropagation； Notes: Implement backprop to compute DVec(Unrolled $$D&#94;1, D&#94;2, D&#94;3$$ ); Implement numerical gradient check to compute gradApprox; Make sure they give similar values; Turn of gradApprox(slower than DVec); Random Initialization: if use zeros(n, 1) to initialize the theta, it would end up with all same delta; Symmetry Breaking: Initialize each $$\\Theta_{ij}&#94;l$$ to a random value in $$[-\\epsilon, \\epsilon]$$ : Theta1 = rand(10,11)*2*init_epsilon - init_epsilon; Work flow: Training a neural netwrok: no. of input units; no. of output units; reasonabel default: 1 hidden or larger, every layer has same units(usually more the better); flow: Rndomly initialize weights; Implement forward prop to get $$h_{\\Theta}(x&#94;i)$$ Implement code to compute cost function $$J(\\Theta)$$ Implement backprop to compute partial derivatives $$\\frac{\\partial J(\\Theta)}{\\partial \\Theta}$$ Use gradient chacking to check Use gradient descent or advanced optimization medhotd with backprop to minimize $$J(\\Theta)$$ as function of $$\\Theta$$ (if $$J(\\Theta)$$ is non-convex, may stuck in local minimum) if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"misc","title":"Learn Neural Network"},{"url":"lr.html","text":"Lineaer Regression Exercises: pause; in matlab is to pause programs;","tags":"misc","title":"Linear Regression"},{"url":"ml-sys-design.html","text":"Machine Learning System Design Priotirizing what to work on(eg. email spam system) How to spend time to make it have low error Collect lost of data E.g. \"honeypot\" project Develop sophisticated features based on email routning info. Email body. (discounts/discount, deal/Dealer, punctuation) Mispelling Error Analysis Implement quickly; Plot learning curves for training and cv data set , more features? more data? Error analysis: look at the eamil misclassified maunally, to design new features; what type of eamil it is(classify them manually) what cues you think would have helped?(steal password) go through features which is important (appears the most often) The importance of numerical evaluation stemming software to detect discodunt/discounters/distcounted as the same word; without stemming(percentage), with stemming(percentage), error metrics Error Metrics for Skewed Data What a joke!: skewed classes(one class has way larger capacity) one of evaluation metrics(one possible solution)===>Precision/Recall: act/pre 1 0 1 True positive False positive 0 Flase negative True negative Definition: $$Precision(rare cases) = \\frac{\\# true\\_positives}{\\# predicted\\_positives}$$ ; $$Recall(rare cases) = \\frac{\\# true\\_positives}{\\# actual\\_positives}$$ High precision / recall means good classifier. if we cheat using predict all of the patient have no cancer, then the recall will be high. - Tradeoff precision and recall(how to control): - improve hypothesis output threshold(0.5->0.9): improve precision, decrease the recall - lower threshold,: avoid false negatives - like ROC/ plot precision vs. recall; - how to decide-> $$F_1$$ score: $$F_1=2\\frac{PR}{P+R}$$ better test on cv dataset to choose the right one 4. Data for machine learning： - Large data rationale: 1. use learning algo with many features(, manually look at the data if feature is enouth for human expert.low bias)； 2. and use a very large training set(low variance); if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"misc","title":"Machine Learning System Design"},{"url":"neural-network.html","text":"Neural Network Hypothesis Representation / Non-linear hypothesis why complex non-linear hypothesis: Some label distribution require non-linear; If the feature number is large, linear regression including non-linear terms would be computationally expensive, that is why we need neural network; Neuron model: input, bias unit, input wires, activation function(h_theta), output Neural network: input layer: $$x_0(bias unit), x_1, x_2, x_3...$$ hidden layer(in between input and output layer): $$a_0&#94;{(2)}, a_1&#94;{(2)}, a_2&#94;{(2)}, a_3&#94;{(2)}...$$ output layer: final layer; Mathematical definition how to represent hypothesis in neural network(matrix computation): $$a&#94;{(j+1)} = g(\\Theta&#94;{(j)}a&#94;{(j)})=g(z&#94;{(j+1)})$$ , input layer is $$a&#94;{(1)}$$ , g is sigmoid function. next layer takes this layers output as features. Use neural network to represent logic unit: by applying different weight between bias unit and input; XOR: exclusive or; XNOR: not(XOR) Multi-Class Classification: multiclass classification using neural networks is an extension of one vs. all method. MATLAB: fmincg(better for large no. of features) Symmetry Breaking if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"misc","title":"Neural Network"},{"url":"photo-ocr.html","text":"Photo OCR Problem Description and Pipeline: optical character recognition(read text from an image) photo ocr pipeline: image -> Text detection -> Character segmentation -> Character classification(A, B, C.....), we can use some modules to apply on our data Sliding Windows: sliding window classifier: aspect ratio = length/width ratio Geting lost of data and artificial data artificial data synthesis for photo ocr(distortion, blurring)- character recoginition; distortion introduced should be representation of the type of noise and distortion in the test set; Discussion on getting more data: Make sure you have low classifier before expending the effort(plot learning curves. e.g. keep increasing the number of features/number of hidden units in neural network until you have a low bias classifier) How much work would it be to get 10x as much data as we currently have. Much better performance artificial data synthesis Collect/label it yourself.(#hours, may not that much, could be a hero) Crowd source(e.g. amazon mechanical turk) websites hire people to label data Ceiling analysis: what part of the pipeline to work on next? what part of the pipeline should you spend the most time trying to improve; over all system accuracy: 72%; text detection accuracy: 89%; character segmentation: 90%; character recognition: 100%, upper bound of accuracy: face recognition from images: camera -> prepreocess(remove bg) -> facedetection -> eyes segmentation -> nose segmentation -> mouth segmentation -> logistics regression -> label ceiling analysis: overall 85%, preprocess 85.1%(using gound-truth labels, to see the final accuracy), face detection 91%... compute the improvement. No gut feeling.","tags":"misc","title":"Photo OCR"},{"url":"recommend-system.html","text":"Recommend System Problem Formulation: Examples: Predicting movie ratings: $$n_u$$ = no. of users, $$n_m$$ = no. of movies, $$r(i, j) = 1$$ if user j rated movie i. $$y(i,j)$$ =rating given by user j to movie i(only if $$r_{ij} = 1$$ ) ;predict unrated score for each movie by each user. Content based recommender systems: action or romance(x_1- romance intense, x_2-action intense) $$x&#94;i\\in\\mathbb{R}&#94;3$$ , so for each user j, learn a parameter $$\\theta&#94;j\\in\\mathbb{R}&#94;3$$ , predict user j as rating movie i with $$(\\theta&#94;j)&#94;Tx&#94;i$$ stars for cern movie Formulation: $$r(i,j)$$ = 1 if user j has rated movie i(0 otherwise) $$y&#94;{(i,j)} = $$ rating by user j on movie i $$\\theta&#94;{j}$$ = parameter vector for user j $$x&#94;i$$ = feature vector for movie i for user j, movie i, predicted rating by $$(\\theta&#94;j)&#94;Tx&#94;i$$ $$m&#94;j$$ = no. of movies rated by user j to learn $$\\theta&#94;j$$ $$\\min\\limits_{\\theta&#94;j}\\frac{1}{2}\\sum\\limits_{i:r(i,j)=1}((\\theta&#94;j)&#94;Tx&#94;i - y&#94;{(i,j)})&#94;2+\\frac{\\lambda}{2}\\sum\\limits_{k=1}&#94;n(\\theta_k&#94;j)&#94;2$$ repeat these processes, to learn $$\\theta&#94;1, \\theta&#94;2, \\theta&#94;3...\\theta&#94;{n_u}$$ : $$\\min\\limits_{\\theta&#94;1, \\theta&#94;2,....\\theta&#94;{(n_u)}}\\frac{1}{2}\\sum\\limits_{j=1}&#94;{n_u}\\sum\\limits_{i:r(i,j)=1}((\\theta&#94;j)&#94;Tx&#94;i - y&#94;{(i,j)})&#94;2+\\frac{\\lambda}{2}\\sum\\limits_{j=1}&#94;{n_u}\\sum\\limits_{k=1}&#94;n(\\theta_k&#94;j)&#94;2$$ Gradient Descents update: $$\\theta&#94;j_k = \\theta&#94;j_k - \\alpha\\sum_{i:r(i,j)=1}((\\theta&#94;j)&#94;Tx&#94;i-y&#94;{(i,j)})x&#94;i_k)$$ for k = 0 $$\\theta&#94;j_k = \\theta&#94;j_k - \\alpha[\\sum_{i:r(i,j)=1}((\\theta&#94;j)&#94;Tx&#94;i-y&#94;{(i,j)})x&#94;i_k) +\\lambda\\theta&#94;j_k]$$ for k = 0 2. Collaborative Filtering: - Probelm Motivation: suppose we dont know the x1 and x2 values for each movie - Optimization Algorithm: - Given $$\\theta&#94;1, \\theta&#94;2....\\theta&#94;{n_u}$$ , to learn x&#94;{i}: $$\\min\\limits_{x&#94;i}\\frac{1}{2}\\sum\\limits_{j:r(i,j)=1}((\\theta&#94;j)&#94;Tx&#94;i - y&#94;{(i,j)})&#94;2+\\frac{\\lambda}{2}\\sum\\limits_{k=1}&#94;n(x_k&#94;i)&#94;2$$ Given $$\\theta&#94;1, \\theta&#94;2....\\theta&#94;{n_u}$$ , to learn $$x&#94;1, x&#94;2, x&#94;3...$$ : $$\\min\\limits_{x&#94;1, x&#94;2,...x&#94;{(n_m)}}\\frac{1}{2}\\sum\\limits_{i=1}&#94;{n_m}\\sum\\limits_{j:r(i,j)=1}((\\theta&#94;j)&#94;Tx&#94;i - y&#94;{(i,j)})&#94;2+\\frac{\\lambda}{2}\\sum\\limits_{i=1}&#94;{n_m}\\sum\\limits_{k=1}&#94;n(x_k&#94;i)&#94;2$$ ; Randomly guess $$\\theta \\rightarrow x \\rightarrow \\theta \\rightarrow x$$ Collaborative Filtering Algorithm: Collaborative filtering optimization objective: solve $$x&#94;i$$ and $$\\theta&#94;j$$ simultaneously=>minimizing $$x&#94;1, x&#94;2,...x&#94;{n_m}$$ and $$\\theta&#94;1, \\theta&#94;2,...$$ simultaneously, $$x\\in\\mathbb{R}&#94;n$$ not n+1, let it learn by itself: Initialize to small random values(x and thetas) Minimize J(x, theta) Vectorization: Low randk matrix factorization Y matrix(movie no. by user no.): $$X\\Theta&#94;T$$ , X = no. movie by no. features, $$\\Theta&#94;T$$ = no. user by no. features Finding related movies, for each product i, we learn a feature vector $$x&#94;i\\in\\mathbb{R}&#94;n$$ how to find movies j related to movie i? Implementation details Users who have not rated any movies Mean Normalization: $$(\\theta&#94;j)&#94;Tx&#94;i + \\mu_i$$ to guess user5(who doesnot rate anyone) if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"misc","title":"Recommend System"},{"url":"systematic-error.html","text":"Papers: Pekka K. Sinervo: Definition and treatment of systematic uncerntainties in high energy physics and astrophysics Robert Cousins: Probability density functions for positive nuisance parameters. Drive home message: Systematic Error Taxonomy: TypeI: essencially statistical error(like acceptance of a detector which could be determined by other measturement which is dominated by statistics) TypeII: like background events: we can assume a \\(p(x_i|\\theta)\\) (and then the maximum likelihood result, \\(L(\\theta) = \\times p(x_i|\\theta)\\) ), here theta could be the mass of a new particle or cross-section of a given interaction, then sometime we may have background counts whichcould be represented effectively by nuisance parameter $$\\lambda$$ , so the pdf becomes \\(p(x_i|\\theta, \\lambda)\\) (and then \\(L(\\theta, \\lamba)\\) ), if we assume \\(\\lambda\\) 's pdf is gamma or lognormal(see Robert's paper, he suggest try all of the methods), we can get marginal pdf of \\(\\theta\\) in form of maximum likelihood function. (Also you can assume prior of \\(\\theta\\) then you are using pure baysian) TypeII: theoretical assumptions(I don't really understand or have no picture in my head) if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"misc","title":"Treatment of systematic error in high energy physics and astrophysics"},{"url":"ubc-decision-tree.html","text":"Decision Trees(UBC courses on youtube) Decision trees(forest) a general tree structure: root node, internal node(split node), terminal node(leaf node) each decision is a line(each line is only slightly better than random guess, combine many of these would be a better algorithms) how to pick attribute(nodes) Entropy: $$H(\\frac{p}{p+n}, \\frac{n}{p+n}) = -\\frac{p}{p+n}log_2(\\frac{p}{p+n})-\\frac{n}{p+n}log_2(\\frac{n}{p+n})$$ for a chosen attribute A, with K distinct values, divides the training set E into subsets E1, E2, ...Ek, Expected Entropy(EH) $$EH(A) = \\sum_{i=1}&#94;K \\frac{p_i+n_i}{p+n}H(\\frac{p_i}{p_i+n_i}, \\frac{n_i}{p_i+n_i})$$ Information gain(IG) or reduction entropy for this attribute is: $$IG(A) = H(\\frac{p}{p+n}, \\frac{n}{p+n}) - EH(A)$$ choose the one increase information the most Using reduction in entropy as a criterion for constructing decision trees; Application of decision trees to classification; if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"misc","title":"Decision Tree"},{"url":"travel-list.html","text":"Slipers; Razor; Toothpaste and toothbrush; Underware and clothes; Phone charger cable; I-20 and passport and driver license; Mug; Deorderant; Books(to read on airplane); Download sufficient videos; Nail cutter; A bag for laundry; Holder for iPhone or GPS; More pants/shorts; Automobile phone charger; to be continued...","tags":"misc","title":"Checklist for travel"},{"url":"fm.html","text":"libFM Manual paper manual","tags":"misc","title":"Factorization Machines"},{"url":"fnal-emc-test.html","text":"Analysis Code: EIC_EM_combined.C : used to plot multiplicity vs. energies and resolution vs. energies. PedestalM.C : change the nadc in line 41. Input: test.txt , test1.txt , test2.txt which are corresponding to high-medium-low-resolutions. Output: pedestal_setting.txt . ReadoutDataM.C : used to plot ADC channel spectra. EIC_macros/ReadoutHistograms.C or EIC_macros/ReadoutHistogramsNewECal.C : Input: data188.txt. Output: data188.txt.root NewECalCalibration.C : Input: .root . Output: plots. Tune cuts in the middle. NewECalAnalysis.C or NewECalAnalysis1.C or NewECalAnalysis2.C : Input: .root files. Output: histograms. TODO: add the setup diagram. Summary All of the code is under directory Documents/2016_FNAL_test/macros_2016 Sdata: Spaghetti detector with 10 degrees Data: 20160506 Code: ReadoutData_2016.C to check the raw data; ReadoutHistogramsNewECal_2016.C to convert the raw .txt files to .root files; NewEcalAnalysis_wide_cuts_batch.C to analyze data, plot spectra from Lead glass or our carolimeter, uniformaty map, deposited energy profile along each side, this script cannot be run alone, you have to modify the batch_regular.C to input the data set files for analysis; pllot_macros_2016.C to plot summary resolution plots and mean values' linearity. Every other directory other than mentioned are corresponding to different data sets, like old_detector , 4degree , rotate (data set after rotating the crack orientation). report directory has the report file and all of the plots attached can be found in word file. For Sdata and rotate data, I already changed the code for pedestal subtraction in NewEcalAnalysis_wide_cuts_batch.C , others if I didn't change the script, the resolution data should be fine still.","tags":"misc","title":"FNAL EMC test"},{"url":"operating-system-notes.html","text":"Tips from Midterm: Need to check the extra material in html format. Also need to check the quiz topics and read related materials. Chapter 32 Common Concurrency Problems what are two major classes of non-deadlock bugs? [ atomicity violation and order violation ] What is the common way to fix order violation problems? [use condition variables.] Deadlock Avoidance What is deadlock-avoidance? [Making case-by-case decisions to avoid deadlocks] What does reservation means in the context of deadlock-avoidance? [] How about over-booking? [] How to deal with rejections of services? [ a. log and exit; b.__keep trying; __c.__return error but continue trying ; __d. reduced requested resource use for civic-minded programs] How deadlock happens? What are the four conditions to make hold for a deadlock to occur [ a. Mutual Exclusion; b. Hold and wait; c. No preemption(locks cannot be forcibly removed from threads that are holding them); d. circular wait ] How to prevent circular wait ? [Set a total ordering on lock acquisition. e.g. L1 always before L2, a specific technique is to use the lock address to enforce lock ordering] ?? What is hold-and-wait ? [incremental allocation of resource may induce deadlock issue. ] How to attack hold-and-wait [Make acquiring all locks atomic. Like put lock around the lock acquisition code. What are the issues? lower the concurrency and you need to know what locks you need to acquire which require knowledge of implementation. ] ?? Will context switch happen in between pthread_mutex_lock(prevention) and pthread_mutex_unlock(prevention) How to attack No Preemption issue? [] What is the use of pthread_mutex_trylock(L2) ? what is difference between it and pthread_mutex_lock(L2) ? [The latter will block if not available , the former will return error code, but if L2 is available, it will grab as pthread_mutex_lock(L2) does. ] What is livelock , compared to deadlock ? [system runs through a certain code sequence again and again but making no progress… Deadlock will not run through code sequence. ] Name a solution to solve livelock ? [add delay to re-loop over the whole thing.] What is the weakness of your method? [It needs know the implementation details and release the required resources. ] How to eliminate need for mutual exclusion ? [With help from hardware. ] What is difference between deadlock prevention and deadlock avoidance ? [] How to use Scheduling to avoid deadlock? [] What is the shortcomings/trade-offs of this kind of scheduling(never schedule threads competing for same lock on one core.)? [performance may be very bad! only useful like in embedded system. ] What does Detect and Recover does to deadlock? [] Health Monitoring and Recovery What is a deadlock? [] How to know if or not system is making progress? [ a. have an internal monitoring agent watch message traffic or a transaction log to determine if or not work is continuing. b. have the service send periodic heart-beat message to a health monitoring system. c. have an external health monitoring service send periodic test requests to the service, to see if or not they are correctly responded in a timely fashion. ] What does it mean by not receiving a heart-beat from process? [ a.__node failed; __b. process failed; c. system gets loaded and message gets delayed; d. network error delay or cancelled the delivery of the message.] What are the issues you need to realize when you do non-disruptive reboots? [ a. up-ward compatibility; b. should equipped with fall-back option to return to the previous release.] What is prophylactic reboots ? [restart nodes one at a time to prevent software system from degrading … which might be due to memory leaks or something else. ] ​ Java synchronization mechanism what is happens-before relationship? [Let A and B represent operations performed by a multithreaded process. If A *happens-before * B, then the memory effects of A effectively become visible to the thread performing B before B is performed.] What is Reentrant Synchronization? [allow itself to reacquire the lock it already owns. ] System Performance Measurement Testing under live loads; Strength and weakness; Chapter 33 Event-Based Concurrency How to build a concurrent application typically? [Using thread, alternative in server/gui based applications, event-based concurrency.] How to receive events? [select() / poll() system calls] What is a blocking system call? [It is meaning that you are going to block the progress of the process until the IO or network stuff gets done.] Why there is a rule that no blocking calls are allowed in event-based system? [Because if one event handler gets blocked, then the whole system will sit idle, wasting large amount of resources. ] What is called asynchronous I/O? [Basically your system call can return immediately and continue doing things until IO gets completed and you can poll or use interrupt to get informed. ] What are the issues about the asynchronous IO? [a. multiple core function., b. conflicts with paging, for example, will block the whole system, then no progress can be made. c. hard to manage over time, for example, if one routine gets changed to blocking from non-blocking, then you need to handle it ] Why it is thought to be difficult to integrate the event-based concurrency with other aspect of modern system like paging? [Learn how to speak in OS languages. ] Why it is said the event-based system gets control of scheduling itself from OS? [Don't know?] What are two approaches to the same concurrency problem ? [events and threads, considering when u have to do things like keep reading requests and writing things, how can accomplish them without concurrent programs. ] Device Drivers: Classes and Services What two abstractions represented by device drivers? [a. Generalizing abstractions: use a few general classes like disks and network interfaces, graphics adaptors; b. Simplifying abstractions: implementation of std class interfaces while hiding the details of a particular device] Why use OOP for device driver development? [For code reuse.] Two major driver classes in old unix systems? [a. block devices. b. character devices] What is DMA request? [Direct Memory Access, which allows certrain hardware subsystems to access main system memory independently of CPU.] Block devices are random-access devices addressable in fixed size[support request() , used in OS, force IO to go through the system buffer cache] Character devices are sequential access, or byte addressable.[support read() , write() , seek() ] What is Disk-Kernel Interface and Device Driver Interface(specific interface for this device. ) Chapter 35. What are three pillars of operating system? [Virturalization, Concurrency, Persistence] What does persistence mean, name examples? [making information persist, despite computer crashes, disk failure, or power outages] Chapter 36. I/O Devices How do graphics or other high performance IO devices connect to system? [ Peripheral Component Interconnect(PCI) or its derivatives ] What bus are lower level or slow devices(mice, disks) connecting to ? [peripheral bus, like Universal Serial Bus(USB), Serial AT Attachment (SATA), Small Computer System Interface(a bus standard, SCSI)] Why we need fast bus and slow bus(hierarchical structure)? [physics(the shorter the faster, so no room for plug devices), cost(engineering cost)] What are two parts in a canonical device? [Interface(Registers of status, command, data, regard them as return value , function and input parameters) and Internals(CPU, DRAM/SRAM, hardware-speicific chips): ] What is polling a device? How to avoid the cost? Why interrupt is not always good? If dont know, use what approach? [keep asking if it is available/finished; Interrupt, put device sleep and let hardware issue an interrup which can effectively put CPU to jump to OS at pre-determined ISR, like reading data or just error code from the device and wake up waiting process; Interrupt will slow down system if device if very fast.] Programmed IO? (CPU involved in data movement. Making computation and I/O overlaped) When interrupts are not bettern than PIO? (cost of handling of interrupts and context switching outweight the benefits; Another one is huge amount of network packets incoming generating initerrupts will overload the CPU and finally make CPU only process these interrrupts and unable to run user processes(livelock); Coalescing ) What is DMA and why DMA? [DMA = Direct Memeory Access; Because if you let PIO do the copy and transfer work, it is a waste of CPU time, DMA has its own engine and os can only telles him where the data, how large is it and where to move to, when DMA finish its job, it will raise an interrupt and os thus knows the transfer is done. ] Two major concerns to incorporate devices into system? [conviences and efficiency. ] How the OS actually communicates with devices? [I/O instructions: in/out instruction to assign the port the data goes to; Memory mapped IO: indicates the device register available as location in memory and hardware then routes it to the real place.] Device driver? Why ? [the lowest level software in OS that knows everything about the device; ] How does device fit into the OS? [Software stack in OS to make os work with devices(from bot to top): device driver(provide protocol-specific r/w)->Generic Block Layer(block r/w)->File System(open read, write, close, etc)->Application ] What is the downside of above approach? [too general so some device-specific feature cannot be enjoyed by the rest of the OS] Protocol to interact with device? [the rules or procedures you have to follow to get what you want from this device.] How should I/O be integrated into systems? What are the general mechanisms? How can we make them efficient? [2 ways to make it efficient and communicate] Chapter 37. Hard Disk Drive What is the interface for the morden hard disk drive? [read/write 512-byte blocks(sector), address space of the drive is from 0 to n - 1, where n is the number of sectors in this drive] What size of write is atomic operation is guranteed by the manufacturer? [512-byte write, write it entirely or nothing at all. But the file system can provide like 4KB size operation.] Some reasonable assumptions we can make for the data access in hard drive? [random access worse than continguous access or sequential read/write, adjacent acess is faster than two random blocks ] What is rotational delay? What is the seek time? What is transfer?[Rottaional delay is desired sector rotates to head's position. These two combined to be the most expensive operations on disk; either write or read to/from disk through the head.] Name a few other designs in hard drive? [track skew, multi-zoned disk drives(each zone has tracks with same number of sectors)] What is the use of cache/track buffer on hard disk? [8-16MB, which is used to store all of the sectors on that track and let accessing them become easier. ] What are write back and write through? [acknowledge the write operation after writting to its cache or disk. ] TODO: computing of the disk access time. What is disk scheduler? What is the difference between job scheduler and disk scheduler? Is it serviced one by one or just by set? What is SJF(shortest job first)? What strategies do we have to do the scheduling? [ Shortest Seek Time First , SCAN , Shortest Positioning Time First ] What are the advantages and disadvantages for each scheduling policy? [a. SSTF: cons-os dont know the geometry of the disk, but can be fixed by nearest-block first algo, starvation can happen if there is a steady stream coming, request to another track can be starved(fairness); b. SCAN: to conquer fairness issues of SSTF, ] What is Elevator or SCAN and F-SCAN and C-SCAN work? [Simply go back forth from outer to inner or inner to outer, service the one when it gets to. F-SCAN is freezing the queue until sweep happens(means it wont schedule if a request come when it is sweeping, so even far-away but early comming requests can be serviced), C-SCAN is just go from outer to inner and again, outer to inner, this can avoid in favor of middle sectors which might be acrossed twice if not circular scan] Why SPTF ? [Because you dont know whether seek time outlarge the rotation time or vice versa. OS dont know for sure, so it is always implemented in drive.] Where does disk scheduling happen in morden system? [disk controller has SPTF implemented and good idea what to service first, so os has a guess and send its guess to the disk and let disk make decision. ] What is IO merging? [merge contiguous requests, done by os or scheduler. ] Chapter 38. Redundant Arrays of Inexpensive Disks (RAIDs) What are the criteria to assess a storage system? [Reliability, Capacity, Performance] What does it mean by transparancy? Can you name an example how it benefits a new system? Why it is said transparency greatly improves deployability? [Transparency means the new functionality demands no changes to the rest of the system. SCSI-based RAID storage array can enable immediate use like a SCSI disk. Your OS and user application don't need to change a line of code to make original version work. ] What are physical IO and logical IO? [These two operations take place on two different software level, the first one takes place on RAID level, the latter takes place on Operating System] What does DRAM mean? [Dynamic Random-Access Memory] What is fail-stop fault model? [a disk has only two states: working or failed] Name three important RAID designs? [RAID Level 0(stripping), RAID Level 1 (mirroring), RAID Level 4/5(parity-based redundncy)] What is the advantages/disadvantages of RAID Level 0? [Upper bound of performance(most parallism )/capacity(round robin place information across the disks), low reliability] How to determine the chunk size? What are the pros/cons for each strategy? [little chunk(high intra-disk parallelism, high positioning time); large chunk(low intra-file parallelism, low positioning time??)] How to assess the performance of different RAID mode? [Considering two metrics: a. single-request latency; b. steady-state throughput of the RAID, total bandwidth of many concurrent requests. (The latter would be the focus in high performance environment. ) ] What is the throughput and latency for RAID Level 0? [N*S and N*R and latency for a single-block request should be the same for single disk result.] What is RAID Level 1 ? [] What are RAID 1+0 and RAID 0+1 ? Assess RAID Level 1 ? [Capacity: half the the peak value; Reliability: Tolerate up to N/2 and at least 1 disk failure; Performance: write latency is different since it has two copies to write(but if done parallel, almost equivalent to single disk); throughput(write and read) is N/2 * S, random read access is N * R, random write access is N / 2 * R ] What is the use of write-ahead log? [To ensure the atomicity of write operation. ] What is RAID Level 4 ? How to assess it? [Using XOR for each bit of blocks on each disk and get the parity block and if one failed, use the remaining blocks to reconstruct the lost one; Capacity: (N-1)*B, Reliability: (N-1)*B, Performance: throughput::read: (N-1)*S mb/s, throughput::write: small write problem (bottleneck is the parity disk), R/2 mb/s(read and write like done on single disk) , latency::read single disk, latency::write half the single disk(4 operations in 2 parallel)] RAID 5 ? Why? Summary of RAID Level Assessment: Chapter 39. Interlude: Files and Directories What are the underlying entries behind the virtualization entities process and address space? [CPU and memory] API used when interacting with a UNIX file system; What are the two key abstractions for virtualization of storage? [file and directory] What is called the inode name? [The file's low level name.] What is the difference between a file and a directory? [it contains a list of tuples (user-readable name, low-level name)] What is the use of lseek() ? Will it cause disk seek? [change the next write/read start position, but will not cause any disk head movement. But certainly will cause it when it comes to the upcoming read and write.] Inode? [a data structure which keeps the all of the metadata for a file on the disk.] Why removing a file is performed via unlink()? [creating a file has two steps: a. create a structure storing metadata on disk, b. link a human name to that file, put the link into a directory; unlink means decrement the reference count by 1 every time you delete a link] Why you can't create a hard link to a directory? Why can't to do this to another partition of hard disk? [a. for the fear that you create a cycle in the directory tree; b. only unique within one filesystem, partition means different filesystem ] How does fs know how many references are out there? [reference count for each file] How many different files types in Unix system? [d, f, l(soft links), it is a file storing the path, longer name = larger size] What does mount() do? [paste the new filesystem to the target point on the existing directory tree. ] Chapter 40. File System Implementation Two aspects you have to consider about building a file system? [ access method and data structure ] Typical size of a block( 4KB) Diagram for a file system? ![Screen Shot 2016-11-19 at 12.21.10 AM](/Users/lwen/Desktop/Screen Shot 2016-11-19 at 12.21.10 AM.png) What is direct pointers? [disk addresses, each pointer referes to one disk block, but if the file that is really big, bigger than block multiplied by the number of direct pointers] Is disk byte addressable? [No, only consist of a large number of addressable sectors, usually 512 bytes.] What is the typical number of direct pointers? [12] What is the shortcoming for single extent file system? [Hard to find contiguous chunk of disk space for a single big file] Compare pointer-based and extent-based approaches? [a. more flexible but more metadata; b. less flexible but more compact] What approach does ext4 use for disk addressing? [extent-based, not like ext2, ext3] Name example file system using linked-based scheme? [FAT: file allocation table.] How does a directory data structure look like on disk? ![Screen Shot 2016-11-19 at 10.10.19 AM](/Users/lwen/Desktop/Screen Shot 2016-11-19 at 10.10.19 AM.png) Does a directory have a inode? [YES] What data structure is used to manage free spaces on disk in vsfs? [bitmap] Things happens when creating a new file? [a. search bitmap, b. mark an inode, c. mark bitmap, all these three should be done by file system. ] What is the inode number for / directory? [No. 2, file system reads this in and traverse the whole structure. ] What is open file table? What does it mean by further update the in-memory open file table for this file descriptor? Update offset? Update last accessed time How many IO generated for each write action? [a. read the bitmap, write the bitmap, read and write to inode, and wrtie the actual block itself.] create may cost 10 IO operations while the write may cost 5 IOs, these are already a lot! What strategies can be used to maintain a fixed-size cache? [LRU, initialized at boot time.] What is the advantage of wrtie buffering. [a. batch some updates into a samller set of IOs; b. buffer the writes in memory can make system schedule the subsequent IOs; c. create and delete, then no need to bother the filesystem to make real changes to the disk, fsync() can enforce the immediate write] What are the ad/disad for static partitioning and dynamic partitioning Chapter 41 Locality and the Fast File System Chapter 42 Crash Consistency FSCK and Journaling. Crash-consistency problem: due to some reason, the system crashed, and some on-disk structure will be left in an inconsistent state. How to deal with this kind of situation. Two approaches? [FSCK: file system checker And journaling, aka write-ahead logging. ] What is the major problem for fsck? [slow and lost one and search the entire system approach.] What is the other name for journaling? [Write ahead logging. ] What are physical logging? [Put all of the things into the block.] What are the checkpointing? [overwrite the on-disk structure] Disk internal schedule may rearrange the order of writing data out to disks. protocol for ext3 update the file system? [journal write, journal commit and check point. ] Free journal block in super-block of journaling. Metadata journaling ? [just write meta data twice instead of data blocks twice also as what data journaling did. protocol is at Page 526] ​ Chapter 43 Log-structred File Systems Why build such a log-structred file system? [a. increasing memory size makes write performance critical because read may end up checking the cache in fact; b. gap between sequential and random IO performances; c. poor performance like FFS has on common workload, like update a file may induce large amount of IOs even though most of the blocks are located in the same group; d. RAID-unaware] How does LFS write sequentially and effectively? [keep track of the memory updates when the change gets cumulated enough, LFS writes it out to the disk all at once. ] Why it is difficult to find an inode on LFS? [Because LFS never overwrites things, so inode is scattering across the whole disk and keeps moving around.but it introduce inode map which just tells you where to find the starting address of a file, and Check point Region. ] How does LFS handle garbage collection? [segment by segment, periodically, writes out the live ones and free up the dead ones. ] How to determine within a segment, which is live which is dead? [in each segment, the segment summary block is used to do so. ] Policy? [cold and hot segment. ] How to recover from accident? [old version snapshot.] Chapter 44 Data Integrity and Protection In early RAID systems, model of failure ? [the whole is working or the entire disk is down. ] What are the latent-sector error(LSEs) and block corruption? [LSEs - due to the head crash, a group of sectors has been damaged in some way. ] How to recover these errors? [LSEs could be easily fixed by using RAID-4/RAID-5 or other mirrored RAID to recover or compute the corrupted data. standard redundancy mechanism. ] Silent failures via data corruption.? How can we detect this kind of corruption? [checksum, CRC or Fletcher checksum...] Variations of checksum layout in hard drive disks? [8 bytes per sector or store multiple blocks in one single block/sector , but this approach performs much poorly demanding two writes. ] Misdirected Writes and lost writes? [redundancy on disks solves first mode of error. checksum again in ZFS (Zetta File System)] What is disk scrubbing? [Periodically check the checksum of files stored in disks to see if they are corrupted or not. ] Overhead of checksumming? [Check P558] Chapter 47 Distributed Systems The major concern or crux when building a distributed system? [Make it look like never fail even some components of it will fail from time to time] Major limitations' causes? [Communication is inherently not reliable, system performance would be very critical, as well as security] Why communication is not reliable? [packets get lost, corrupted or just to the destination simply because of a couple of reasons. Like, electrical problems to cause bit flipped, cable, routers. or lack of buffering. ] how to deal with communication failures? Or in other words, how to build a reliable communication layer? [Acknowledgement. work with timeout to resend the messages. but this has its own shortcoming because one message could be sent twice if ack gets lost, so the receiver or the sender should have some mechanism to deal with this issue, like sequence counter, TCP/IP is an example. ] How to avoid overwhelming the server? [exponential back-off scheme to set up a timeout. ] What is DSM(Distributed Shared Memory)? Why is it not used anymore ? [Failure happens on one machine would end up losing some pages on that machine, performance which would be largely impacted by communication between machines. ] What the hell is Remote Procedure Call? [Two main components: stub generator and run-time library. ] Reliable or unreliable communication protocol to build RPC on top of it? [Unreliable for efficiency. ] Issues may need the RPC to handle is ?[timeout: by check server state periodically, large arguments: fragmentation and reassembly, byte-ordering: ] When does a normal procedure call happen?[compile time] When does RPC happen？[Run-time.] Chapter 48 Sun's Network File System(Mainly NFSv2) Why bother distributed file system? [a. Data sharing; b.centralized administration(backup data); c. security, ] How to build a distributed file system? [a. transparent filesystem to client side, open, read, write, close, mkdir; ]![Screen Shot 2016-11-28 at 2.47.51 PM](/Users/lwen/Desktop/Screen Shot 2016-11-28 at 2.47.51 PM.png) Why server crashed? [a. bugs; b. just look like it crashed, due to the disconnection. ] Why stateless approach for NFS? [Hard to deal with crash recovery. ] File handle components? [a.volume identifier; b. inode number; c. generation number, these three together comprise a unique indentifier informs the server which file system the request refer to(volume identifier), which inode number, generation number is used to reuse an inode number by incrementing it every time it is called. ] by incrementing it whenever an inode number is reused, the server ensures that a client with an old file handle can't accidentally access the newly-allocated file.???? Very important figure 48.5GOD's SAKE What does close() do? [clean up local data structures, like free descriptor \"fd\" in open file table. Does it need to call server? Hell no. ] What is called idempotent operation? [result of multiple idempotent operation is equal to one operation. ] What would happen if a server's reply gets lost? [client would send it again and wait for the reply. ] What is the cause of cache consistency problem? [cache, ] What are examples of cache consistency problems? [update visibility(not written to center immediately, so other node still gets the old copy), stale cache(maybe some has been updated in the file server, but you still have stale version in your fucking cache).] How to solve them? [a. update visibility=> flush-on-close, ensures the open operation on the other node gets the newest version. b. check before using its cached content. by sending a getattr request., use attribute cache, in which each entry would expire after every 3 seconds.] What is the shortcoming of close-on-read? [quicky generated and deleted files may not be needed to be written to file server so this may harm the overall performance.] What is the shortcoming of attr cache implementation? [maybe just hard to understand its behavior, sometimes its correct version, sometime it is old version. ] What is the major performance bottleneck of NFS server? [write performance, because server will send back success only after committing the changes to storage. So solution could be use battery backed memory to hold the change and send back quickly the success message. or use a filesystem which is designed to write to disk quickly when one finally needs to do so. ] What is the philosophy of NFS? [simple and fast crash recovery. ] Chapter 49 The Andrew File System(AFS) Why NFS is limited by its scalability? [Because the frequent check for the cache validation may limit the number of clients a server can respond to.] How to deal with cache consistency in AFS? [Every time an application open a file, it is in its latest version.] One of the basic principle of all versions of AFS is what ? [whole-file caching] In AFSv1, how does it improve its performance after first access to a file? [ask if it has been changed, if not, will use locally copied version.] Problems with first version of AFSv1? [a. Too high costs in Path-traversal b. The client issues too many TestAuth protocol messages to test if that file is already modified or not. ] What is callback? Why? [a. A promise from the server to the client that the server will inform the client when a file that the client is caching has been modified. No need for client to contact server any more. ] Wha tis FID， file identifier? [volume identifier, file identifier, and a uniquifier. no need to traverse path name every single time????![Screen Shot 2016-11-29 at 1.11.15 AM](/Users/lwen/Desktop/Screen Shot 2016-11-29 at 1.11.15 AM.png)] When will file server update the file? [when flush back to file when a close() is issued. But on the same machine, it can immediately see the changes.] Wha tis last writer wins? [or last close wins] Why server crash is a big event? [callbacks are stored in memory, so when rebooted, no idea which client has which file, so solution could be heartbeat messages or broadcast the invalid messages to clients. ] Very very important comparison between NFS and AFS in this chapter, worthy of second reading!!!! What kind of workload is not welcome in AFS? [sequential accessed or random updates]","tags":"misc","title":"Operating System Notes(Three Easy Peieces)"},{"url":"fermi-lab-calor-test.html","text":"Log: Only two ADC blocks, each having 16 channels. To get the pedestal, run disabled zero-suppression to get the pedestal_setting.txt , then run zero-suppression test to get the real signals. We also have to change the resolution of ADCs, high resolution = low range, so we have to choose the appropriate resolution to record all of the data. Don't click Stop DAQ To run the PedestalM.C we have to change the No. of ADCs(probably we can improve it). For zero-suppression mode, slot3 and slot7 are wrong for some reason, it is like hardware issue. Check lw_ped_enabled_slot3_slot7.txt for details.","tags":"misc","title":"Fermi Lab Calorimeter Test"},{"url":"effective-cpp-notes.html","text":"Log 2016-03-26: Item21, dont try to return object reference when you have to return an object 2016-03-27: Item13, use objects to manage resources: std::auto_ptr<Investment> or std::tr1::shared_ptr<Investment> last one is preffered for its normal copy behaviour 2016-03-28: Item20, prefere pass-by-reference-to-const to pass-by-value; the former is better over the latter because it is efficient(vector copy will copy all of the objects they are pointing to) and avoid slicing problem(only copy base classes); pass-by-value is better for built-in types(even user-defined object is small). 2016-03-29: Item27, minimizing casting, static_cast and dynamic_cast(performance poor, up and down), static_cast can only to down or implicit conversion. prefer c++ style. 2016-03-30: Item2, prefer consts, enums, and inlines to #define s. Or prefert compiler to pre-processor. Reasons: 1. Hard to track it down; 2. in-class definition is not allowed except the integer/char/bool types. Instead you can do like const double CostEstimate::FudgeFactor = 1.35 ; 3. define an enum in class is also okay as the size of an array. 4. Prefer inline to #define thing. 2016-03-31: Item20, issues you need to consider in type/class design. 2016-04-01: Item7, declare destructor virtual in polymorphic base classes: Always make base class destructor virtual. STL classes(string, vector things) have no virtual destructor though, so never derive from them. Also, you always can implement pure virtual function in abstract base classes in spite of you still have to implement them in derived classes but sometime you may use the abstract class' implementation. 2016-04-18: Item 15: provide acccess to raw resources in resources managing classes: implicit conversion function using operator FontHandle() const to convert Font toi handle type; Diamond problem which stems from multiple inheritance, we can do like class transmitter: virtual public device and class reciever: virtual public device to ensure there is only one base class object in modem class which is defined as class modem : public transmitter, public receiver , check this for more. ++i is more efficient thant i++ ; long double > double > float > unsigned long int > long int > unsigned int > int > char 9.","tags":"misc","title":"Effective C++ Notes"},{"url":"kaggle-competition-toolbox-documentation.html","text":"Directories Structure Kaggle_toolbox | |- raw_data # raw data and extracted 'y' and 'id' | | | |- test.csv | | | |- train.csv... | |- src | | | |- general_to_xgb.py # used to convert genral format(for sklearn) of feature/label to DMatrix | | | |- generate_ens0.py # generate ens0 feature files | | | |- generate_feature0.py # generate #0 features set | | | |- generate_train_y_and_id.py # generate train y and id | | | |- train_predict_xgb.py # train and predict using xgb | |- build # store preprocessed data | | | |- feature # preprocessed feature files go to this folder | | | | | |- feature0.test.feature # feature file for feature set0 | | | | | |- ens0.train.feature # features used for ens0 | | | |- test # predictions from test dataset | | | | | |- xgb_10_0.1_0_0.5_0.4_80_feature0.test.y # predictions for test data set using feature set #0 and xgb algorithm with listed parameters | | | | | |- xgb_10_0.1_0_0.5_0.4_80_feature0.test.soft.y # soft predictions(probability) for test dataset | | | |- val # predictions from training dataset | | | |- xgb_10_0.1_0_0.5_0.4_80_feature0.val.y | |- tests # test code goes to here | |- Makefile, Makefile.feature.ens0, Makefile.feature.feature0... How to Run $make -f Makefile pre1 to extract id and y ; $make -f Makefile.feature.feature0 feature0 to extract feature0 set for xgb , sklearn , fm and other different algorithms interfaces $make -f Makefile.xgb param_tuning_grid/param_tuning_rand/submission/train_predict to do the prediction, you have to change the parameters at the beginning and the feature name in the include statement Logs: 2016-03-26: Implement SVM and other algorithms","tags":"misc","title":"Kaggle Competition Toolbox Documentation"},{"url":"root-tips.html","text":"Log 2016-02-12: this page has a typo: \"values\" -> \"valsue\". 2016-02-12: ROOT Manual P275, indented code not correctly.","tags":"misc","title":"ROOT Tips"},{"url":"server-maintenance-note.html","text":"Info: Passcode for sudo : hint(old one or same as the login passcode) Log: 2016-02-10: Create an account( fengzhao ) for Feng, pwd is 123456, copied his old directory to /media/old_home/fengzhao 2016-08-29: Move fengzhao directory to /media/disk_2016_6T by sudo tar cvzf fengzhao.tar.gz ./fengzhao/","tags":"misc","title":"Server Maintenance Note"},{"url":"unix-server-maintenance.html","text":"Tips e2label /dev/sda DISK_YUAN to label filesystems and in /etc/fstab , you can add entry like LABEL=DISK_YUAN /media/Disk_Yuan ext4 auto,rw 0 0 to automatically mount filesystems. fdisk -l shows all of the accessible filesystems on this computer Log: 2016-02-05 e2label/dev/mapper/fedora-home OLD_HOME this disk actually is the new bought one(3T), but it shows several bad sectors at very beginning, add this entry using label to /etc/fstab","tags":"misc","title":"Unix Server Maintenance"},{"url":"some-facts-about-star-data.html","text":"AuAu200GeV Run11 Time Periods: Period1: <= 12138024 Period5: 12154021-12165031 Period6: >12165031","tags":"misc","title":"Some Facts about STAR data"},{"url":"cs32-miscellaneous-information.html","text":"Seasnet Windows Desktop On windows: Connect to ucla vpn Click the Remote Desktop Connection application which is coming with Win8+ Type remote.seas.ucla.edu Enter seaslab\\classlwe and passcode To scp the files, using WinSCP Host name is lnxsrv07.seas.ucla.edu and account classlwe and passcode Drag the file you want to drag Tips: Include guard We need like: #ifndef MAP_INCLUDED #define MAP_INCLUDED #endif to prevent double declaration from happening, this is the first thing coming to my mind why asked why we needed it. cyclic declaration The typical scenario is like: class has student data member, but student also has class enrolled data member, so you have to declare one first. #include \"Foo.h\" class Foo ; //You have to #include the header file defining a class when //* you declare a data member of that class type //* you declare a container (e.g. a vector) of objects of that class type //* you create an object of that class type //* you use a member of that class type class Blah { //... void g ( Foo f , Foo & fr , Foo * fp ); // just need to say class Foo; //... Foo * m_fp ; // just need to say class Foo; Foo * m_fpa [ 10 ]; // just need to say class Foo; vector < Foo *> m_fpv ; // just need to say class Foo; Foo m_f ; // must #include Foo.h Foo m_fa [ 10 ]; // must #include Foo.h vector < Foo > m_fv ; // must #include Foo.h }; void Blah :: g ( Foo f , Foo & fr , Foo * fp ) { Foo f2 ( 10 , 20 ); // must #include Foo.h f . gleep (); // must #include Foo.h fr . gleep (); // must #include Foo.h fp -> gleep (); // must #include Foo.h } delete pointer usually, delete pointer will free allocated memory, but the pointer is undefined. char * c = new char [ 5 ]; delete [] c ; // delete array; initialize class pointer copy and swap String & String :: operator = ( const String & rhs ){ if ( * this != rhs ){ String tmp ( rhs ); swap ( tmp ); } return * this ; } tips to switch typedef(TODO) pass by reference Sometime, we dont want to cost space to copy some big object into a fucntion, so we just pass the argument by reference. Constructor: if you don't define ctor for a class, compiler will generate one(no parameter) default constructor for you Virtual function will propagate, but better indicate virtual \"string\" , 'char' , double quotes are array of constant characters, single quotes are char, neither of them is string type, static has three usages: 1. static in function; 2. static in class(class-wise, not instance-wise) 3. static in file Map::insert(const KeyType& key, const ValueType& value) allows you pass a temporary object to this function. For instance: map.insert(Coord(40, 20), 43); . But if you want to pass your temporary object to a non-constant reference, you will get compilation error. Since if you want to pass it to a non-reference, you are implicitly stating that you want to modify the object and return it to its caller. This is completely meaningless. Map::insert() takes O(N) time as well as Map::erase() , this is where I made a mistake in homework4. To count a string's length, use std::string::size() which measure how many characters in the string(no '\\0' included); strlen(const char*) counts number of chars until null terminator. int main(int argc, char** argv) is equal to int main(int argc, char* argv[]) , so argv[1] will take out the second string passed to the main function. How to write sprintf -like code in c++? std :: ifstream ifile ( \"blah.txt\" ); std :: string line ; while ( ! getline ( ifile , line )){ std :: istringstream is ( line ); if ( ! ( is >> string1 >> string2 >> string3 )) std :: cout << \"bad formatted line\" << std :: endl ; int int_dec = std :: stoi ( string1 . c_str (), nullptr , 10 ); //int int_hex = std::stoi(string1.c_str(), nullptr, 16); //int int_bin = std::stoi(string1.c_str(), nullptr, 2); double do = std :: atof ( string2 . c_str ()); float fl = std :: stof ( string3 . c_str ()); } A complete example: #include <fstream> #include <sstream> #include <iostream> #include <string> #include <cassert> #include <iomanip> int main (){ std :: ifstream ifile ( \"fio_file_input.txt\" ); if ( ! ifile ) std :: cout << \"so Bad!\" << std :: endl ; std :: string line ; int int_dec ; double dou , fl ; while ( getline ( ifile , line )){ std :: cout << line << \" happy!\" << std :: endl ; std :: istringstream is ( line ); std :: string string1 , string2 , string3 ; if ( ! ( is >> string1 >> string2 >> string3 )) std :: cout << \"bad formatted line\" << std :: endl ; int int_dec = std :: stoi ( string1 . c_str (), nullptr , 10 ); //int int_hex = std::stoi(string1.c_str(), nullptr, 16); //int int_bin = std::stoi(string1.c_str(), nullptr, 2); dou = std :: stod ( string2 . c_str ()); fl = std :: stod ( string3 . c_str ()); std :: cout << int_dec << \" \" << std :: setprecision ( 13 ) << dou << \" \" << std :: setprecision ( 13 ) << fl << std :: endl ; } //assert((dou+fl) == (323224.3 + 4343.43545465)); }","tags":"misc","title":"CS32 Miscellaneous Information"},{"url":"proton-omega-correlation.html","text":"Production Code Location: rcf:/gpfs/mnt/gpfs01/star/pwg/lwen1990/omg_proton_cor How to Run It: ./batchjobs/submit_pomg.sh 20160114 166 or you can just run ./generate_Period1.sh to automatically produce dataset within certain time window in terms of daynumber. Log 2016-02-03 Update the Scheduler_pomg.xml to include .sl64_gcc482 compiled software instead .sl64_gcc477 package. Generate 166 data(Period6) 2016-02-10: on rcf, generate_Period1.sh is running to produce Period1(day132-140) data for this analysis.","tags":"misc","title":"Proton Omega correlation"},{"url":"the-hunting-of-the-quark.html","text":"\\(K_0\\) has strangeness +1 while \\(\\Lambda&#94;0\\) having -1; Kaon and pion or three pions resonances are constituting the vector mesons with spin-1, because it has preferred direction in space. Kstar-kaonpion, Rho-pionpion, omega-pionpionpion, these are three vector mesons which were discovered earliest if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"misc","title":"The Hunting of the Quark"},{"url":"support-vector-machine.html","text":"Overview Hypothesis: $$h_\\theta(x) = 1 \\text{ if } \\theta&#94;Tx\\geq 0; 0 \\text{ otherwise}$$ Two new functions: Optimization Objective: $$\\min\\limits_{\\theta}C\\sum\\limits_{i=1}&#94;{m}[y&#94;i\\text{cost1}(\\theta&#94;Tx)+(1-y&#94;i)\\text{cost0}(\\theta&#94;Tx)] + \\frac{1}{2}\\sum\\limits_{i=1}&#94;{n}\\theta_i&#94;2$$ SVM with Kernels Usually we choose Gaussian kernel and use training data points as landmarks to compute feature \\(f_i = e&#94;{-\\frac{||x-l_i||}{2\\sigma&#94;2}}\\) (i = 1...m samples, we use training samples as landmarks \\(l_i\\) ) Hypothesis: Given x, compute features \\(f \\in R&#94;{m+1}\\) , predict \\(y_i=1\\) if \\(\\theta&#94;Tf \\geq0\\) Loss Function: $$\\min\\limits_{\\theta}C\\sum\\limits_{i=1}&#94;{m}[y&#94;i\\text{cost1}(\\theta&#94;Tf)+(1-y&#94;i)\\text{cost0}(\\theta&#94;Tf)] + \\frac{1}{2}\\sum\\limits_{i=1}&#94;{m}\\theta_i&#94;2$$ Poly kernel： \\(k(x, l) = (x&#94;Tl+constant)&#94;{degree}\\) so two parameters. More kernels: String kernel(string classification), chi-square kernel, chi-square kernel, histogram intersection kernel chi-square kernel, histogram intersection kernel... SVC(Support Vector Classifier) in scikit-learn Usage Example: clf = SVC(C=1, kernel='rbf', gamma='auto') Take-home message: Tune gamma(if 'rbf' kernel( \\(\\text{exp}(-\\gamma||x-x&#94;{\\prime}||&#94;2)\\) ) is set); Tune C, the regularization term; Preprocessing your data to [0, 1] or [-1, 1] or { \\(\\mu\\) : 0, \\(\\sigma\\) : 1} 'class_weight'(SVC only): used for unbalanced data(way more positives than negatives) Large Margin Classifier(SVM)(C is very large, emphasize the first term in cost function, may overfit for outlier) Before passing your data to SVC, make sure your array is C-ordered contiguous by nparray.types For the return values by the clf.predict , it is ordered by the integer labels so the first one is the label with samllest integer, if y is continuous, an error will be raised. decision_function: default is 'ovr' = one-vs-rest. how to represent the decision boundary on two features plots(linearly separatable) why this optimization leads to large margin classifier? MATH behind tlarge margin classification vector inner product: imagine, if C is large(less likely to be biased, but high variance), the optimization is becoming obj = \\(\\min\\limits_{\\theta}\\frac{1}{2}\\sum\\limits_{j=1}&#94;n\\theta_j&#94;2 = \\frac{1}{2}||\\theta||\\) , s.t. \\(\\theta&#94;Tx&#94;i\\geq1, if y&#94;i=1\\) and \\(\\theta&#94;Tx&#94;i\\leq-1 if y&#94;i = 0\\) , i means the condition should be satisfied by each data point(x, y), see how svm choose decision boundary how svm choose decision boundary: Kernels I Non-linear decision boundary: Kernel: given x, compute new feature depending on proximity to landmarks( \\(l&#94;1, l&#94;2, l&#94;3\\) ): Given x: \\(f_1 = exp(-\\frac{||x-l&#94;1||&#94;2}{2\\sigma&#94;2})\\) ....similarity function, kernel(k(x, \\(l&#94;i\\) )), Gaussian kernels Example: Kernel with SVM use training point as landmarks, for each training data point , get a new set of coordinates( \\(\\vec{f}\\) ) Hypothesis: Given x, compute features f(m+1 dimensions), predict positive if $$\\theta&#94;Tf\\geq0$$ $\\ Training: \\(\\min\\limits_{\\theta}C\\sum\\limits_{i=1}&#94;{m}y&#94;icost_1(\\theta&#94;Tf&#94;i)+(1-y&#94;i)cost_0(\\theta&#94;Tf&#94;i) + \\frac{1}{2}\\sum\\limits_{i=1}&#94;{m}\\theta_i&#94;2\\) kernels for logitics regression lack tricks in SVM SVM parameters: C(1/lambda): large C-low bias and high variance; small C-higher bias, low variance \\(\\sigma&#94;2\\) : large-vary more smoothly, higher bias, lowervariance and verse visa Using an svm need to specify: choice of parameterC; choice of kernel(no kernel = linear kernel, n large, m small, nolinear may overfit): if Gaussian kernel, you should choose sigma squre(n small, m large): do perform feature scaling before using the Gaussian kernel; other choice of kernel: need to satisfy called Mercer's Theorem to make SVM packages' optimizations run correctly; very rare to use other kernels: polynomial kernal( \\(k(x, l) = (x&#94;Tl+c)&#94;n\\) , two parameters, c and n, only when x, l non-negative); more esoteric(string kernel, chi-square, histogram intersection kernel) Multi-class classification: many svm packages already have built-in mc classification functionality, otherwise, use one-vs.-all, pick classi with larges \\((\\theta&#94;i)&#94;Tx\\) Logistic regression vs. SVMs: n= no. of features, m = no. of training examples: n is small, m is intermediate, use svm with Gaussian kernel(up to 50000), if n is small, m is large, /add more features , then use l-r or svm or svm with linear kernel(convex optimization for all svm but not for neural network) otherwise(n is large) neural network works in most settings, but slow if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"misc","title":"Support Vector Machine"},{"url":"gradient-descent.html","text":"Problem Setup: Have some function(loss functions): \\(J(\\theta_0, \\theta_1)\\) and want to minimize it So we start off with some random values of \\(\\theta_0\\) and \\(\\theta_1\\) . Repeately do \\(\\theta_j = \\theta_j - \\alpha\\frac{d J(\\theta_0, \\theta_1)}{d\\theta_j}\\) we have to do this for different variables simultaneously What is stochastic gradient descent? if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"misc","title":"Gradient Descent"},{"url":"clustering-pca.html","text":"Clustering Unsupervised learning unlabeled training set: Training Set := \\(\\{x&#94;1, x&#94;2, x&#94;3, x&#94;4...\\}\\) market segmentationm social network analysis organize computing clusters anstronomical data analysis K-Means Algorithms(most famous algo of clustering) cluster centroids(randomly initialized) if you want to split it into 2 groups(two centroids) and computer the distance from those centroids; move centroids to means in each group; Definition: Input: k(number of clusters); training set \\({x&#94;1, x&#94;2, x&#94;3, ...}\\) Randomly initialize K cluster centroids \\(\\mu_1, \\mu_2,...\\in\\mathbb{R}&#94;n\\) where n is the dimension of each data point(ignore the \\(x_0&#94;i = 1\\) ) Repeat :::matlab % puseudocode for i = 1:m c(i) = index(from 1 to K) of centroids closeset to x(i) end for k = 1:K mu(k) = means(points in cluster k)% |x-x|&#94;2 end K-means for non-separated clusters(Tshirt size: height/weight, cluster data to determine the population of each size) Optimization objective: \\(c&#94;i\\) = index of cluster to which example \\(x&#94;i\\) is currently assigned; \\(\\mu_k\\) = cluster centroid k( \\(\\mu_k\\in\\mathbb{R}&#94;n\\) ); \\(\\mu_{c&#94;i}\\) = cluster centroid of cluster to which example \\(x&#94;i\\) has been assigned Cost function: \\(J(c&#94;1, c&#94;2...c&#94;m, \\mu_1, \\mu_2...\\mu_K) = \\frac{1}{m}\\sum\\limits_{i=1}&#94;{m}||x&#94;i - \\mu_{c&#94;i}||&#94;2\\) will always decrease with increasing iteration loops. How to intialize K-means? Should have K < m; Randomly pick K training examples; Set $$\\mu_1, ....\\mu_K$$ equal to these K examples, randomize the indices; Local optima issue; Random initialization: :::matlab for i = 1: 100 randomly initializae K-means run K-means, get c(1), c(2)..., c(m), mu(1), mu(2)...,mu(k) compute cost function end pick the clustering that gave you the minimum cost function How to choose the number of Clusters What is the right value of K? Elbow method: J vs. K(no. of clusters) -> choose the elbow point; sometimes its hard to distinguish the elbow point Based on a metric for how well it performs for that later purpose(like tshirt sizes, small, medium, large, OR xs, s, m, l, xl); P rincipal C omponent A nalysis(PCA) UL Motivation I: Data compression Reduce data from 2D to 1D: x1 and x2 is very linear, project the data points to fitting straight lines(z1): $$x&#94;1\\in\\mathbb{R}&#94;2 \\rightarrow z&#94;1 \\in\\mathbb{R}...$$ , make learning more quickly; Reduce data from 3D to 2D(1000D ->100D): $$x&#94;i\\in\\mathbb{R}&#94;3$$ project these data to a plane and assign them z1 and z2 from the coordinates from thsi projected plane; UL Motivation II: Data Visularization 2D/3D Principle Component Analysis: Problem Formulation: Reduce from 2D to 1D: find a direction onto which to project the data so as to minimize the projection error // Reduce from nD to kD :...... to minimize the projection error;= lower dimensional surface; Difference from linear regression: vertical distance or distance from that straight line PCA Algorithm: Data preprocessing: 1. mean normalization; Compute \"covariance matrix\": $$\\Sigma = \\frac{1}{m}\\sum\\limits_{i=1}&#94;{m}(x&#94;i)(x&#94;i)&#94;T$$ (x is n by 1 vector) cmopute \"eigenvectors\" of matrix $$\\Sigma$$ : [U, S, V] = svd(Sigma) , singular value decomposition to find the eigenvalues, more computationally stable, sigma is a n by n matrix(n is original data dimension), U is a n by n, what we want; take first k column from U to from a new matrix $$U_{reduce}$$ : $$z&#94;i = U_{reduce}&#94;Tx&#94;i $$ Reconstruction from Compressed Representation $$x_{approx} = U_{reduce}z$$ Choose proper k of principal components: Average squared projection error: $$\\frac{1}{m}\\sum\\limits_{i=1}&#94;n||x&#94;i - x&#94;i_{approx}||&#94;2$$ Total variation in the data: $$\\frac{\\frac{1}{m}\\sum_{i=1}&#94;m ||x&#94;i - x&#94;i_{approx}||&#94;2}{\\frac{1}{m}\\sum_{i=1}&#94;m ||x&#94;i ||&#94;2} \\leq 0.01$$ called: 99%(95%/90%) of variance is retained; ALgorithm: try pca with k = 1, compute the percentage of variance(<= 0.01); repeat and increase k, until you get the 99% variance is retained. [U, S, V] = svd(Sigma) , the S matrix, for given k, the percentage of variance can be computed by $$1-\\frac{\\sum&#94;k_{i=1} S_{ii}}{\\sum&#94;n_{i=1} S_{ii}} \\leq 0.01$$ why we need to retain the variance?? Advice for applying PCA supervised learning speedup: $$(x&#94;1, y&#94;1), (x&#94;2, y&#94;2)...(x&#94;m, y&#94;m)$$ , extract dataset: $$x&#94;1, x&#94;2...x&#94;m\\in\\mathbb{R}&#94;{10000}$$ to $$z&#94;1, z&#94;2...z&#94;m\\in\\mathbb{R}&#94;{1000}$$ ; new dataset $$(z&#94;1, y&#94;1)...$$ Applications of PCA: Compression: 1. reduce memory/disk needed to store data; 2. speed up learning algo; Visualization: To prevent overfitting(bad), you should use regularization! Bad Practice: we should do the whole thing without using PCA, try raw daat with whatever you want to , only if theat doesnt do what you want, then implement PCA and consider using $$z&#94;i$$ if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"misc","title":"Clustering and PCA"},{"url":"anomaly-detection.html","text":"Density Estimation: Anomaly detection: Problem Motivation: Aircraft engine features example \\({x&#94;1, x&#94;2, x&#94;3....}\\) , Is \\(x_{test}\\) ok or not? Or fraud detection, \\(x_i\\) = features of user i; s activities. Model p(x)(probability) from data, identify unusual users by checking which has \\(p(x) < \\epsilon\\) ; Monitoring computers in a data center: memory use, CPU load, CPUload/network_traffic, number of disk accesses/sec; Manufacturing Gaussian Distribution: \\(x\\sim N(\\mu, \\sigma&#94;2)\\) , \\(p(x;\\mu, \\sigma&#94;2)=\\frac{2}{\\sqrt{2\\pi}\\sigma}exp(-\\frac{(x-\\mu)&#94;2}{2\\sigma&#94;2})\\) Anomaly Detection Algorithms: Training set: \\({x&#94;1, x&#94;2,....x&#94;m}, x&#94;i\\in\\mathbb{R}&#94;n\\) \\(P(x_1, x_2, ...) = p(x_1; \\mu_1, \\sigma&#94;2_1)p(x_2...)=\\prod p(x_i;\\mu_i,\\sigma_i&#94;2)\\) those parameters can be estimated by \\(\\mu_j = \\frac{1}{m}\\sum\\limits_{i=1}&#94;m x_j&#94;i, \\sigma_j&#94;2=\\frac{1}{m}\\sum\\limits_{i=1}&#94;m (x&#94;i_j-\\mu_j)&#94;2\\) It is a anomaly if \\(P(x)<\\epsilon\\) ; Develope and evaluate an anomaly detection system: Assume we have some labeled data, of anomalous and non-anomalous examples(y = 0 if normal, y = 1 if anomalous) Training set: \\(x&#94;1, x&#94;2, x&#94;3...\\) cross validation set: test set: example: 10000 good engines, 20 flawed engines, training set: 6000 good engines, cv: 2000 good 10 flawed, test: 2000 good 10 flawed; data is very skewed algo evaluation: 1.fit p(x); 2.on a cv test example, predict based on \\(\\epsilon\\) Anomaly Detection vs. Supervised Learning very small number of positive examples(y=1), large number of negatives -> anomaly detection -> many different types of anomalies, hard for any algorithms to learn from positive examples, future anomalies look nothing like any of the anomalous examples large number of positive AND negative examples, enough positive examples for algo to get a sense of what postive examples are like: email spam claasification, weather prediction, cancer classification Choosing what features to use: non-gaussian features - transform it error analysis for anomaly detection: monitoring computers in a data center: \\(x1 = memory\\_use\\) , \\(x2 = number\\_of\\_disk\\_accesses/sec\\) , \\(x3 = cpu\\_load\\) , \\(x4 = network\\_traffic\\) , \\(x5 = cpu\\_/network\\) , \\(x6 = cpu&#94;2/network\\) ... Multi-variate Gaussian Distribution Formulation: \\(x\\in\\mathbb{R}&#94;n\\) , don't model p(x_1), p(x_2)...separately, model p(x) all in one go. $$P(x;\\mu,\\Sigma) = \\frac{1}{\\sqrt{2\\pi}&#94;{n/2}|\\Sigma|&#94;{1/2}}exp(-\\frac{1}{2}(x-\\mu)&#94;T\\Sigma&#94;{-1}(x-\\mu))$$ positive or negative correlation observed from sigma matrix(off-diagonal elements) Anomaly Detection using the Multivariate Gaussian Distribution original model corresponds to a special case of multivariate gaussian distribution where off diagonal elements are zero is sigma matrix so multivariate gaussian can automatically capture the correlations between features. but original is computationally cheaper(n = 10000),must have m > n , or else sigma is non-invertible. original one has no this restriction. Redundant features may make sigma non-invertible. 2 solutions to non-invertible sigma(a. m >= 10n, b.find redundant features) if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"misc","title":"Anomaly Detection"},{"url":"algorithms-comparison.html","text":"This note is dedicated to comparing different supervised machine learning algorithms which will usually used in Kaggle competitions. Some overview points Some aspects you have to consider about what model to choose: i. Number of features; ii. Number of samples; iii. Amount of noises; iv. Wethear the data is linearly separable or not; Five main steps to train a algorithm: i. Selection of features; ii. Choosing a performance metric; iii. Choosing a classifier or algorithm; iv. Evaluating an algorithm; v. Tuning an algorithm. Todo: Hypertune to tune the xgboost/early_stopping.(Learn to use it or leave a code example)","tags":"misc","title":"Algorithms Comparison"},{"url":"frequencist-or-bayesian-for-a-nuclear-experimentalist.html","text":"What problem is this note aiming to answer? Problem : How to construct confidence level for measured quantities? This note is based on the paper written by Robert Cousins $/home/lwen/gdrive/ml_particle/bayesian.pdf Problem of measuring mass When we measure an elementary particle's mass, the measuring aparatus yields values( \\(m\\) ) normally distributed around true mass \\(m_t\\) , the pdf can be expressed this way: $$p(m|m_t) = \\frac{1}{\\sqrt{2\\pi\\sigma&#94;2}}exp(\\frac{-(m-m_t)&#94;2}{2\\sigma&#94;2})$$ So normally, we want to construct a confidence interval \\((m_1, m_2)\\) at a specified confidence level(C.L.). In this note, we take it to be 68%. Classical C.L.(Neyman, 1937): No matter what \\(m_t\\) is , if we do many many same experiments and construct C.L. each time, 68% of the those C.L.s will cover the true value. If we assume \\(m\\) follows p.d.f. of normal distribution with mean \\(m_t\\) and standard variance \\(\\sigma\\) , the likelihood function will be like: \\(L(m_0, m_1, ...m_n|m_t) = \\prod_{i=0}&#94;{n}\\frac{1}{\\sqrt{2\\pi\\sigma&#94;2}}exp(\\frac{-(m_i-m_t)&#94;2}{2\\sigma&#94;2})\\) The likelihood is differing from pdf is it considers \\(m_t\\) is changing given the particular data set \\(m_i\\) . Usually the measured value is taken as the value maximizing the likelihood \\(L\\) or equivelently \\(ln L\\) . So the rub comes in chossing how to extract errors(C.L.), especially when it is not parabolic. Classical take: Two Case Studies: Case I. Exponential Distribution Actually, if we measure the isotope decay rate, we can find the distribution is exponential decay \\(f(t) = e&#94;{-t/\\tau}\\) , and the likelihood function finally will yield \\(\\frac{\\sum t_i}{n}\\) for the estimate of parameter \\(\\tau\\) : $$ln L(t_i|\\tau) = ln(\\frac{1}{\\tau&#94;n}e&#94;{-\\frac{\\sum t_i}{\\tau}}) = -nln(\\tau) - \\frac{\\sum t_i}{\\tau}$$ If we compute the derivative of this function we can find the maximum is reached when \\(\\tau = \\frac{\\sum t_i}{n}\\) . Similarly, if the mean value of \\(t_i\\) is obeying Gaussian distribution and it's variance also can be compute analytically by \\(var[\\tau] = E[\\tau&#94;2] - E[\\tau]&#94;2\\) , since we know the likelihood function, this expression can be evaluated exactly and it turns out \\(\\tau&#94;2/n\\) , so use the prevously measured \\(\\tau\\) , we can get 68% C.L. interval. The normal question regarding this precedure is why this variance is correct? Because the mean value is following Gaussian distribution, so we can think this way: the likelihood function is the approximation of final Gaussian function, we use analytical expression to get the relationship between the know parameter \\(\\tau\\) and invisible parameter \\(\\sigma\\) . Case II. Gaussian Distribution Assuming the measured mass \\(m\\) from this experiment(from likelihood method) is obeying Gaussian distribution, our goal transforms to estimate the parameters( \\(\\sigma_mean\\) ) of function: $$g(m_{mean}) = \\frac{1}{\\sqrt{2\\pi\\sigma_{mean}&#94;2}}exp(\\frac{-(m_{mean}-m_t)&#94;2}{2\\sigma_{mean}&#94;2})$$ The likelihood method yields results \\(\\hat{m_t} = \\sum m_i/Nobs\\) and \\(\\sigma_{mean} = \\sum(m_i-\\hat{m_t})&#94;2 / n\\) . This case differs from last one in computation of variance of result. In this example, the sigma value is obtatined by maximizing the likelihood function while last one used analytical calculation. In most cases, a p.d.f.'s variance is not a separate parameter to be estimated, so analytical approach is a more comman way to evaluate the result's standard deviation(error) by assuming it's following Gaussian distribution. Note the difference between above equation and the single observation p.d.f., basically, we are assuming the mean value is obeying the normal distribution, so if we can get the optimal variance \\(\\sigma\\) for one-time observation, we can get the \\(\\sigma_{50} = \\frac{\\sigma}{\\sqrt{50}}\\) which is accounting for the standard deviation of the results we repeat this experiment with 50 observations many times again. So basically if we report our result like: \\(m_t = 40.0 \\pm 0.5\\) with many many observations per experiment, we are equally saying if we repeat this experiment 1000 times, about 680 out of them will yield results falling within that range. This is also why we may increase statistics to make our result more precise(decrease the standard deviation). All of these are based on Gaussian distribution assuption. Take home message: no matter what p.d.f. it is for single observation, the experiment results will bedistributed normally, and the mean value is the Maximum Likelihood estimator distribution, and \\(\\sigma\\) is the variance estimator \\(E[x&#94;2] - E[x]&#94;2\\) , since likelihood function is the estimator p.d.f which will coverges to normal distribution. Refer to Cowan's Statistical Data Analysis page 75(exponential decay example's variance computation).. $$ln L(\\hat{\\theta}\\pm N\\sigma_{\\hat{\\theta}}) = ln L_{max} - N/2$$ Central Limit Theorem Bayesian take: We can construct posterior(to-estimate parameter's distribution): $$P(m_t|m) = L(m|m_t)\\times P(m_t)/\\int L(m|m_t)P(m_t)dm_t$$ So if we take prior as uniform distribution, we can simplify the expression like: $$P(m_t|m) \\sim L(m|m_t)$$ So we can construct C.L. from this posterior. From the above plots, we can find if we are measuring a mass which in no way to be negative, we can construct the posterior as shown in plot3, so that we can normalize that function to get final distribution. Then the C.L. can be constructed easily, since posterior is already the p.d.f. of the measuring parameters. Example I. Neutrino Mass Measurement Some collaboration reported result like \" \\(m&#94;2 = -56\\pm\\) \" if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"misc","title":"Frequencist or Bayesian for a nuclear experimentalist"},{"url":"sklearn-note.html","text":"Preprocessing Standarlization SVM/L1, L2 regularizers of linear models assume that all features are centered around zero and have variance in the same order. Two approaches: sklearn.preprocessing.scale and sklearn.StandardScaler() The firest one will transform data to center around zero with unit variance. The latter can reapply the same transformation to test dataset if tyou fit it to train data first. Regression LassoCV :::python","tags":"misc","title":"sklearn Note"},{"url":"matplotlib-cheatsheet.html","text":"Primer python Visualization Ecosystem Chaco: build interactive applications To make plot inline for Python 3.X: %matplotlib notebook For those familiar with ROOT, fig is like TCanvas object and axis is like TH1D import matplot fig = plt.figure() fig, axes = plt.subplots(2, 2) for axis in axes: axis.hist(np.random(50), nbins=20, color='black', alpha=.3)","tags":"misc","title":"matplotlib Cheatsheet"},{"url":"virtualenvwrapper-cheatsheet.html","text":"Why virtualenvwrapper? Sometime we may work on different projects which require different versions of prerequisite packages, then if you have only on global development environment, you will run into troubles to manage all of these libraries. virtualenvwrapper provides a good solution to this kind of dillema by isolating development environments for different projects. Installation $pip install virtualenvwrapper or $sudo pip install virtualenvwrapper Configuration Add lines to your .bashrc or other shell startup files: export WORKON_HOME = $HOME /.virtualenvs export PROJECT_HOME = $HOME /Dev #TODO source /usr/local/bin/virtualenvwrapper.sh The first environment variable WORKON_HOME is used to store all of the virtual environments you create. Quick-start Create a virtual environment: $workon test -p /usr/local/bin/python3.4 Check all installed packages: $pip freeze Install new packages: $pip install pelican markdown Quit virtual environment: $deactivate","tags":"misc","title":"virtualenvwrapper Cheatsheet"},{"url":"python-for-data-analysis-note.html","text":"This note is based on Python For Data Analysis written by Wes McKinney Chapter1. Preliminaries Why python for data analysis? Ans: pandas + general purpose programming strength. Glue:?? Domain-specific language-MATLAB, R, oftentimes, people will do research, prototype and test new ideas using R or MATLAB and then later port these ideas to a larger production system written in Java/C++. Python can do both, making scientists and technologist use same programatic tools. When to avoid Python? Parallel computing, ??? Multithreded and process, cpu-bounded thread. Essential Python Libraries: NumPy: ndarray, element-wise computations, read/write array-based data sets to disk, linear algebra operations, FFT, random number generators, tools to connect C/C++/Fortran code to Python; ndarray is used to pass data between algorithms. pandas: rich data structures and functions. Major data structure->DataFrame, a two dimensional tabular, column-oriented data structure with both row and column labels. Combines SQL and numpy's advantages. Sophisticated indexing functionality. matplotlib: generate publication quality plots. IPython: enhanced Python shell and accelerate the writting and testing and debugging of Python code. SciPy: a collection of packages addressing a number of different standard problem domains in scientific computing, scipy.integrate , scipy.linalg , scipy.optimize , scipy.signal , scipy.sparse , scipy.special , scipy.stats , scipy.weave ...Together with NumPy, they form a reasonably complete computational replacement for much of MATLAB along with some of its add-on toolboxes. Chapter5. Getting Started With pandas 2 mostly used data types: Series, DataFrame. We can view DataFrame as a dict of Series. So basically you can construct a DataFrame like: df = DataFrame({'a':[1, 2, 3], 'b':['CA', 'NY', 'NV']} df = DataFrame({'a': {1: 1, 3: 3}, 'b': {1: 'CA', 2: 'NY', 3: 'NV'}}) the outer key is the column and inner one is row Retrieve rows/columns: row = df.ix['a'] or `` For code like df.loc[df['Name'] == 'Bob', 'Sex'] = 1 , we can understand this in python.pandas to reference elements. can exploit boolean array like {False, True, True...} . Apply function and mapping: f = lambda x : x . max () - x . min () df . apply ( f , axis = 0 ) # axis = 0(column-wise, 1 is row-wise) is default, you can omit it in your practice df [ 'animals' ] = df [ 'food' ] . map ( lambda x : meat_to_animal [ x . lower ()]) #Another example is df_train_age [ 'Sex' ] = df_train_age [ 'Sex' ] . map ({ 'female' : 0 , 'male' : 1 }) . astype ( int ) #Below is less professional #df_train_age.loc[df_train_age['Sex'] == 'femal', 'Sex'] = 0 Confusion about the axis definition: df . mean ( axis = 1 ) # apply the mean method on each row, and get the value to show on screen df . drop ([ 'Name' , 'ID' , 'Fare' ], axis = 1 ) # apply the drop action on each row, i.e., for each row, drop the corresponding labels. Some tips on indexing into DataFrame: data = df [ 'Age' ] . iloc [ i ] # is used to retrieve ith row, 'Age' column data = df [ i , 'Age' ] # Wrong, illegal. data = df . loc [ i , 'Age' ] # Correct To distinguish axis in pandas, you should consider below examples: In [ 0 ]: df = pd . DataFrame ({ 'col1' : [ 1 , 2 , 3 ], 'col2' : [ 4 , 5 , 6 ], 'col3' : [ 7 , 8 , 9 ]}) In [ 1 ]: np . mean ( df , axis = 0 ) Out [ 0 ]: col1 2 col2 5 col3 8 dtype : float64 In [ 2 ]: df . mean ( axis = 1 ) Out [ 9 ]: 0 4 1 5 2 6 dtype : float64 In [ 3 ]: df . drop ( 'col3' , axis = 1 ) Out [ 11 ]: col1 col2 0 1 4 1 2 5 2 3 6 So basically, you can understand this way: if axis = 0 , you apply the actions to each column(it will not succeed if the action is not legal), if axis = 1 , then the action will be applied on each row. Let's still take 7th item as an example: In [ 20 ]: df [ df [ 'col1' ] == 1 ] Out [ 20 ]: col1 col2 col3 0 1 4 7 So df['col1'] == 1 is like a pandas.Series of booleans: n [ 21 ]: df [ 'col1' ] == 1 Out [ 21 ]: 0 True 1 False 2 False Name : col1 , dtype : bool Binary logical operations: df_train_age = df_final [ ~ np . logical_or ( df_final [ 'Age' ] . isnull (), df_final [ 'Fare' ] . isnull ())] . copy () # Not below df_train_age = df_final [ ~ ( df_final [ 'Age' ] . isnull () or df_final [ 'Fare' ] . isnull ())] . copy () df.values will return a numpy array([[row]]). If followed by a tolist() method, you will get a nested list","tags":"misc","title":"Python for Data Analysis Notes"},{"url":"python-cheatsheet.html","text":"This cheatsheet is mainly based on the book Writing Idiomatic Python. by Jeff Knupp. Control Structure if x <= y <= z: is legal and efficient; is_generic_name = name in ('Tom', 'Dick', 'Harry') is equivalent to: if name == 'Tom' or name == 'Dick' or name == 'Harry' : is_generic_name = True if my_list: instead of if my_list == []: if position is not None: value = 1 if foo else 0 just like x? True:False in C++ for loop(???format function): for index , element in enumerate ( my_contaniter ): print ( '{} {}' . format ( index , element )) Mutable objects: list, dict, set and most class instances Immutable objects: string, int, tuple Dont use mutable object as the default value for a function argument. def f(a, L=None) instead of def L(a, L=[]) Return expression instead of values to be concise. return a == b == c if not 'happy' in cur_dict: is equivalent to happy is not in the current dictionary. Why use if __name__ == '__main__': Dealing with data No reason to use temporary variable to swap varibles' values: (b, a) = (a, b) Chain string functions: formatted_book_info = book_info.strip().upper().replace(\":\", \"by\") Use ''.join(result_list) Use ord function to convert char to ASCII or vice versa. How to format strings in python: use + operator to concatenate strings and variables. 'old-style' string ''.join(string_list) The best way to do is to use output = 'Name: {user.name}, Age: {user.age}, Sex: {user.sex}'.format(user=user) . This link is very helpful. some_list = [element + 5 for element in some_other_list if is_prime(element)] Prefer list comprehensions to the built-in map() and filter() functions Use sum() function which is built-in Use all(list) or any(list) to check if all of the elements or any one element is equal to True Use a dict as a substitue for a switch ...case statement. return long expression is preferred. log_severity = configuration.get('severity', 'Info') user_email = {user.name: user.email for user in users_list if user.email} Set operations A|B, A&B, A-B, A&#94;B return(set(get_list_of_most_active_users()) & set(get_list_of_most_popular_users())) users_first_names = {user.first_name for user in users} How to define a variable arguments function: In [ 0 ]: def foo ( * args , ** kwargs ): ... : for a in args : ... : print a ; In [ 1 ]: foo ( 1 , 2 , 3 ) 1 2 3 In [ 7 ]: def bar ( * args , ** kwargs ): for a in kwargs : print ( kwargs [ a ]) ... : In [ 8 ]: bar ( 1 , 2 , 3 ) In [ 9 ]: bar ( num1 = 1 , num2 = 2 , num3 = 3 ) 1 2 3 P48 example very impressive (user, name, _, _) = get_user_info(user) is better than (user, name, temp, temp2) = get_user_info(user) tuple can be used to accept upacked list. (name, age, sex) = list_from_comma_separated_file return (mean, median, variance) to return multiple values from one fucntion. Reread class part. Very helpful but hard at this point of time(https://www.jeffknupp.com/blog/2013/04/07/improve-your-python-yield-and-generators-explained/) for uppercase_name in (name.upper() for name in usernames) is better than for uppercase_name in [name.upper() for name in usernames] Organize Your Code Use capital letters when declaring global constant values. Format your code according to PEP8. $sudo easy_install pep8 and $pep8 myfirstpythonprogram.py ! from foo import * << from foo import (a, b ,c, d) < import foo Make use of __init__.py to initialize your package. If you have a package contating large amount of modules but only a few of them are meant to be used by clients, you should use __init__.py : like import gzimo.clinet as Gzimo , so client can write like import Gzimo instead of nested expressions. Use if __name__ == '__main__' to make a script executable. Under if __name__ == '__main__' you should write sys.exit(main()) Use sys.argv to parse command line parameters Use os.path to deal with directory paths. Use automated test tool like the standard library providing unittest should suffice Use self.assertEqual(a, b) instead of self.assertTrue(a == b) Structure of your code What a typical project look like structurally? README environment . yml Makefile setup . py src / __init__ . py src / core . py src / helpers . py docs / conf . py docs / index . rst tests / test_basic . py tests / test_advanced . py What is the use of environment.yml ? conda env create -f environment.yml What is the use of Makefile ? An example is: test : test.py test .PHONY : test What is the use of setup.py ? python setup.py build && python setup.py install == make && make install What is the use of __init__.py ? This file will be loaded and executed when any module of this package, some top-level statements will be executed. After this, it will look for the core.py to execute the statements in core.py . But usually it is left empty.","tags":"misc","title":"Python Cheatsheet"},{"url":"pipi-gamma.html","text":"Data Raw Data Location: /media/Disk_Chen/Data/200GeV_run11/data_minbias5_new/*.flow.nt.root Generated Data Location: lwen@giant:/home/lwen/Analysis/pi_pi_gamma/Cen*/*root Code Please check repository: https://github.com/wenliwen64/pipi_gamma.git Running Instruction i. $cd pipi_gamma/StLPVPlotMaker ii. $root -l run.C Notes: You can change the centrality number in run.C: maker->Init(n_cen, n_jobs) Toy Monte Carlo Model simulation study on MSC observable with Fuqiang's method. some questions: 1. Why use two subevents, one for event plane reconstruction and one for v2 calculation? Ans: stupid if you use the full event plane you will get positive v2, if you define the event plane orientation by \\(\\Phi_{ep} = atan2\\frac{\\sum_i w_i sin2\\phi_i}{\\sum_i w_i cos2\\phi_i}/2\\) ! 2. The Modulated Sign Correlator(msc) is defined as below: $$msc = (\\frac{\\pi}{4})&#94;2(\\lt S_\\alpha S_\\beta\\gt_{in} - \\lt S_\\alpha S_\\beta\\gt_{out})$$ Explanation: 1. \\(S_\\alpha S_\\beta\\) is standing for the cos term sign of correlated particle \\(\\alpha\\) or \\(\\beta\\) Procedures: 1. Input the rp orientation = 0; 2. QA histograms: i. `TH1D* hmsc = new TH1D()` to get the distribution of msc so that we can check if the gamma is close the value of msc. east/west ep, west/east v2, compute msc ii. `TH2D* hmsc_v2 = new TH2D()` so that you may fill this by `hmsc_v2->Fill(east_v2, msc)` event-by-event Log Data Points AuAu200GeV MinBias5 Run11 Data Gamma Delta Kappa_killer if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"misc","title":"Pipi Gamma"},{"url":"git-cheatsheet.html","text":"This article is for people who already get familiar with git to certain extent but still need some quick reference at work. Some Key Concepts SHA-1 value or so-called checksum is used for reference to commit; master branch is the main branch you are working on; HEAD is the tip of current branch(we may have multiple branches at same time). We can move HEAD around and then start recording. So remember, before you move HEAD pointer, you have to store the git log master information properly. Because you will not be able to find them out when you move your HEAD back, i.e., you can find information at HEAD and before HEAD. Maybe you can find the information.? Yes, git reflog will give all of the information you need(mainly the SHA-1 value) to do git reset HEAD SHA-1 Snapshots instead of Changes: Git is storing the snapshots of projects status in different commit instead of the changes regarding each files. So if one file stays unchanged from last commit, git will only store the pointer pointing to it in last commit. Not like other version control system which will only record the difference of each file in each commit. The three states: There are three main sections in a git projects: the Git directory, the working directory, and the staging area: 1. Git directory: place for Git to store the metadata and object database for your project. Basically you copy this directory when you are cloning a repository; 2. Working directory: this is a single checkout of one version of the project. You can add or modify files whatever your want; 3. Staging area: staging area is a file where stored winofrmation about what will go into your next commit. It is sometimes referred to as \"Index\" Basic Git workflow: 1. You modify files in your working directory; 2. You stage the files, adding snapshots of them to your staging area; 3. Commit those changes, which takes the files as they are in the staing area and stores that snapshot permanently to your git direcitory Some terms: 1. committed : a particular version of a file is in the Git directory; 2. staged : the modified file is added into the staging area; 3. modified : If a file was changed since it was checked out but has not be staged, it is called modified Handy Commands To show the changes between working directory and staged changes: $git diff is working vs. cached(staged); $git diff -cached commit_sha is staged vs. commit; $git diff commit_sha is working vs. commit. In git diff : --- and +++ mean old version and new version Use git rm and git mv to delete and rename files. Because if you only use /bin/rm , you will also have to git add these files. git rm does this in one step. git checkout -- index.html ??? git reset HEAD file.txt is to rest the file.txt(staged) back to HEAD state, this doesnt affect the working directory. ??? git checkout SHA-1 -- filename git revert HEAD-3 is to apply opposite changes and commit a new commit. Use merging instead of revert git reset --soft SHA-1 just changes the HEAD position; git reset --mixed SHA-1 is taking something to staged directory. git reset --hard SHA-1 is taking something to staged directory and working direcotry. Add !index.html to eliminate the file from ignore file list. git log -p SHA-1 is to see the difference git dif sha..sha is to compare the two commits. git merge branch1 is to merge branch1 into master. git branch -m branch_old branch_new is to rename and git branch -d branch_to_delete is to delete the branch. git merge --abort is to abor the merge. If not, you have to fix the conficts and do the commit to finish merging. git remote add origin https://....... is to add the remote repository with alias origin . git push -u origin master is to push the master branch to remote repository and keep tracking it. \"keep tracking\" means when other ppl do fetch they can see this branch. git branch -r is to show the remote branches; git branch -a is to show all branches. git clone is to copy the repository like when you are going to contribute to open source project. git pull = git fetch + git merge origin/master is to merge the remote HEAD to your current branch. git push origin non_tracking:non_tracking is to rename the branch name; so git push origin :non_tracking will delete the non_tracking branch; git log -p feedback..origin/feedback is to compare the remote and local repository git rm --cached filename is to remove file from index. Integrated Collaboration Workflow Sometime we can use this workflow between different machines we are working on... Me: > git checkout master > git fetch > git merge origin/master > git checkout -b feedback_form ...do some stuff > git commit -am \"Add customer feedback form\" > git fetch > git push -u origin feedback_form # -u is for the first time Lynda: > git checkout master > git fetch > git merge origin/master > git checkout -b feedback_form origin/feed_back > git log > git show 84b6adf0 ...do some stuff > git commit -am \"Add tour sector to feedback form\" > git fetch > git push Me: > git fetch > git log -p feedback_form..origin/feedback_form > git merge origin/feedback_form > git checkout master > git fetch > git merge origin/master > git merge feedback_form > git push Some Awkward Scenarios to Deal with If you mistakenly commit a big file, what you can do to fix it? :::sh git How to move or remove files? Undoing Things Uncommit things: Scenario 1 : You committed something too early and possibly forgot to add some files, or you messed up your commit message: > git commit -m 'initial commit' > git add forgotten_file > git commit --amend These commands will make you end up with a single commit which contains all of the changes and the second commit will overwrite the previous one. Unstage things: Scenario 2 : You changed two files and want to commit them separately. But you accidently type git add * and stage them both. So how to unstage them? > git add * > git status On branch master Changes to be committed: ( use \"git reset HEAD &lt;file&gt;...\" to unstage ) renamed: README.md -> README modified: CONTRIBUTING.md reset the CONTRIBUTING.md file > git reset HEAD CONTRIBUTING.md Unstaged changes after reset: M CONTRIBUTING.md > git status On branch master Changes to be committed: ( use \"git reset HEAD <file>...\" to unstage ) renamed: README.md -> README Changes not staged for commit: ( use \"git add <file>...\" to update what will be committed ) ( use \"git checkout -- <file>...\" to discard changes in working directory ) modified: CONTRIBUTING.md Unmodifying a Modified File Scenario 3 : What if you realize that you don't want to keep your changes to the CONTRIBUTING.md file? Or you just easily revert it back to what it look when you last commit? > git checkout -- CONTRIBUTING.md > git status On branch master Changes to be committed: ( use \"git reset HEAD &lt;file&gt;...\" to unstage ) renamed: README.md - & gt ; README Note: this is kinda dangerous since it will discard anything changed. Usage of git-stash Scenario 4 : When you have been working on part of your project, things are in messy state but you want to switch branches for a bit to work on something else.You dont want to do a commit. > git status Changes to be committed: ( use \"git reset HEAD &lt;file&gt;...\" to unstage ) modified: index.html Changes not staged for commit: ( use \"git add &lt;file&gt;...\" to update what will be committed ) ( use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory ) modified: lib/simplegit.rb So next step is to issue the git stash command > git stash Saved working directory and index state \"WIP on master: 049d078 added the index file\" HEAD is now at 049d078 added the index file ( To restore them type \"git stash apply\" ) Now the working directory is clean, i.e., you can switch branches: > git status # On branch master nothing to commit, working directory clean Check the stash list: $ git stash list stash@ { 0 } : WIP on master: 049d078 added the index file stash@ { 1 } : WIP on master: c264051 Revert \"added file_size\" stash@ { 2 } : WIP on master: 21d80a5 added number to log Come back to previous state( git stash apply stash@{2} ): $ git stash apply # On branch master # Changed but not updated: # (use \"git add &lt;file&gt;...\" to update what will be committed) # # modified: index.html # modified: lib/simplegit.rb # Git Submodules Usually, we need external library to be included in your working project. Otherwise customer of your software would need to download the shared lib you used. In this site, I have two separate subdirectories(pelican-themes, pelican-plugins) to be submodules. The workflow is like below: Fork the getpelican/pelican-themes and getpelican/pelican-plugins ; In your working directory or parent directory, git submodule add git@github.com:wenliwen64/pelican-themes and git submodule add git@github.com:wenliwen64/pelican-plugins ; You can check the file .gitmodules where store the information about where is the remote repository for the submodule; Go into your submodule directory, apply commands git submodule init + git submodule update ; Change directory to parent directory and git push origin master --recurse-submodules==on-demand ; On another machine, do git clone git@github.com:wenliwen64/pelican_site.git --recurse ; If you want to make change to the themes you have to fork it on github first. Git conflict resolution","tags":"Programming","title":"Git Cheatsheet"},{"url":"titanic.html","text":"This is the content of my super blog post. Data Preprocessing print how are you babe ? Analysis happy? Results Discussion TODO List: decouple learning and prediting processes for trainning data set; retreive best parameter combination from RandomSearchCV for later use; One-Hot-Coding?","tags":"Kaggle","title":"Titanic Survival Prediction"}]}